{
 "cells": [
  {
   "cell_type": "code",
   "id": "79d7ea38",
   "metadata": {
    "deletable": false,
    "editable": false,
    "execution": {
     "iopub.execute_input": "2024-12-09T07:28:05.539816Z",
     "iopub.status.busy": "2024-12-09T07:28:05.539232Z",
     "iopub.status.idle": "2024-12-09T07:28:06.864598Z",
     "shell.execute_reply": "2024-12-09T07:28:06.863609Z"
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-12-11T18:13:41.409001Z",
     "start_time": "2024-12-11T18:13:40.031955Z"
    }
   },
   "source": [
    "# Please do not change this cell because some hidden tests might depend on it.\n",
    "import os\n",
    "\n",
    "# Otter grader does not handle ! commands well, so we define and use our\n",
    "# own function to execute shell commands.\n",
    "def shell(commands, warn=True):\n",
    "    \"\"\"Executes the string `commands` as a sequence of shell commands.\n",
    "     \n",
    "       Prints the result to stdout and returns the exit status. \n",
    "       Provides a printed warning on non-zero exit status unless `warn` \n",
    "       flag is unset.\n",
    "    \"\"\"\n",
    "    file = os.popen(commands)\n",
    "    print (file.read().rstrip('\\n'))\n",
    "    exit_status = file.close()\n",
    "    if warn and exit_status != None:\n",
    "        print(f\"Completed with errors. Exit status: {exit_status}\\n\")\n",
    "    return exit_status\n",
    "\n",
    "shell(\"\"\"\n",
    "ls requirements.txt >/dev/null 2>&1\n",
    "if [ ! $? = 0 ]; then\n",
    " rm -rf .tmp\n",
    " git clone https://github.com/cs236299-2024-winter/lab2-2.git .tmp\n",
    " mv .tmp/tests ./\n",
    " mv .tmp/requirements.txt ./\n",
    " rm -rf .tmp\n",
    "fi\n",
    "pip install -q -r requirements.txt\n",
    "\"\"\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "17155f61",
   "metadata": {
    "deletable": false,
    "editable": false,
    "ExecuteTime": {
     "end_time": "2024-12-11T18:13:41.896046Z",
     "start_time": "2024-12-11T18:13:41.417387Z"
    }
   },
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook()"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "raw",
   "id": "8b105a51",
   "metadata": {
    "id": "8b105a51",
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "%%latex\n",
    "\\newcommand{\\vect}[1]{\\mathbf{#1}}\n",
    "\\newcommand{\\cnt}[1]{\\sharp(#1)}\n",
    "\\newcommand{\\argmax}[1]{\\underset{#1}{\\operatorname{argmax}}}\n",
    "\\newcommand{\\softmax}{\\operatorname{softmax}}\n",
    "\\newcommand{\\Prob}{\\Pr}\n",
    "\\newcommand{\\given}{\\,|\\,}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f3c7d9",
   "metadata": {
    "id": "c8f3c7d9",
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "remove_for_latex"
    ]
   },
   "source": [
    "$$\n",
    "\\renewcommand{\\vect}[1]{\\mathbf{#1}}\n",
    "\\renewcommand{\\cnt}[1]{\\sharp(#1)}\n",
    "\\renewcommand{\\argmax}[1]{\\underset{#1}{\\operatorname{argmax}}}\n",
    "\\renewcommand{\\softmax}{\\operatorname{softmax}}\n",
    "\\renewcommand{\\Prob}{\\Pr}\n",
    "\\renewcommand{\\given}{\\,|\\,}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082484a4",
   "metadata": {
    "id": "082484a4",
    "tags": [
     "remove_for_latex"
    ]
   },
   "source": [
    "# Course 236299\n",
    "## Lab 2-2 – Recurrent neural networks by hand"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728ee5b0",
   "metadata": {
    "id": "728ee5b0"
   },
   "source": [
    "You've read about recurrent neural networks (RNN), but there's nothing like carrying out the calculations yourself to really understand what's going on in these systems.\n",
    "\n",
    "In this lab, you'll carry out RNN calculations by hand or by programming – both forward (calculating outputs from inputs) and backward (computing gradients)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97da1bce",
   "metadata": {
    "id": "97da1bce"
   },
   "source": [
    "New bits of Python used for the first time in the _solution set_ for this lab, and which you may therefore find useful:\n",
    "\n",
    "* [`torch.clamp`](https://pytorch.org/docs/stable/generated/torch.clamp.html#torch.clamp): restricts all elements of a tensor to a specific range\n",
    "* [`torch.diag`](https://pytorch.org/docs/stable/generated/torch.diag.html#torch-diag): creates a tensor with the given inputs as the diagonal\n",
    "* [`torch.eye`](https://pytorch.org/docs/stable/generated/torch.eye.html#torch-eye): creates an identity matrix\n",
    "* [`torch.mv`](https://pytorch.org/docs/stable/generated/torch.mv.html#torch-mv) (typically invoked via the `@` operator): matrix-vector multiplication\n",
    "* [`torch.prod`](https://pytorch.org/docs/stable/generated/torch.prod.html#torch-prod): takes the product of elements in a vector\n",
    "* [`torch.T`](https://pytorch.org/docs/stable/generated/torch.t.html#torch.t): returns the transpose of a tensor\n",
    "* [`torch.zeros`](https://pytorch.org/docs/stable/generated/torch.zeros.html#torch-zeros): creates a matrix of zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2a302b",
   "metadata": {
    "id": "bc2a302b"
   },
   "source": [
    "# Preparation – Loading packages"
   ]
  },
  {
   "cell_type": "code",
   "id": "21250349",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "editable": false,
    "execution": {
     "iopub.execute_input": "2024-12-09T07:28:06.868520Z",
     "iopub.status.busy": "2024-12-09T07:28:06.867941Z",
     "iopub.status.idle": "2024-12-09T07:28:09.773915Z",
     "shell.execute_reply": "2024-12-09T07:28:09.773006Z"
    },
    "id": "21250349",
    "outputId": "490f39dc-a5ec-4256-8b84-28b6fe630f8d",
    "ExecuteTime": {
     "end_time": "2024-12-11T18:13:45.323918Z",
     "start_time": "2024-12-11T18:13:41.931274Z"
    }
   },
   "source": [
    "import sys\n",
    "import torch\n",
    "import wget\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import csv\n",
    "\n",
    "from datasets import load_dataset\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import WordLevel\n",
    "from tokenizers.pre_tokenizers import WhitespaceSplit\n",
    "from tokenizers.trainers import WordLevelTrainer\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "from collections import Counter\n",
    "from tqdm.auto import tqdm\n",
    "import copy\n",
    "\n",
    "# Script for visualizing computation graphs\n",
    "data_dir = \"data/\"\n",
    "sys.path.append(data_dir)\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "wget.download('https://raw.githubusercontent.com/nlp-236299/data/master/scripts/makedot.py', out=data_dir)\n",
    "from makedot import make_dot\n",
    "\n",
    "# Fix random seed for replicability\n",
    "SEED=1234\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/236299/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x12a2481f0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "Z3C5AdGOp5Bd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-12-09T07:28:09.777370Z",
     "iopub.status.busy": "2024-12-09T07:28:09.776729Z",
     "iopub.status.idle": "2024-12-09T07:28:09.784543Z",
     "shell.execute_reply": "2024-12-09T07:28:09.783666Z"
    },
    "id": "Z3C5AdGOp5Bd",
    "outputId": "efc2fa8a-094d-4199-d76d-bd0cce9e7693",
    "ExecuteTime": {
     "end_time": "2024-12-11T18:13:45.335Z",
     "start_time": "2024-12-11T18:13:45.332018Z"
    }
   },
   "source": [
    "## GPU check\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "8b426386",
   "metadata": {
    "id": "8b426386"
   },
   "source": [
    "# RNN calculations by hand – the forward step\n",
    "\n",
    "A _recurrent neural network_ (RNN) works by calculating a sequence of hidden states $\\vect{h} = \\langle h_0, \\ldots, h_N \\rangle$ and outputs $\\vect{o} = \\langle o_1, \\ldots, o_N \\rangle$ from a sequence of inputs $\\vect{x} =  \\langle x_1, \\ldots, x_N \\rangle$. (We're notating the elements, like $x_t$, $h_t$, and $o_t$ as if they are scalars, but you should keep in mind that they might well be vectors themselves.)\n",
    "\n",
    "\n",
    "<img src=\"https://github.com/nlp-236299/data/raw/master/Resources/rnn-unfolded-figure.png\" width=500 align=right />\n",
    "Each hidden state $h_t$ and output $o_t$ of an RNN is calculated from an input $x_{t}$ and the previous hidden state $h_{t - 1}$ using a set of weights $\\vect{U}$, $\\vect{V}$, and $\\vect{W}$ according to the following equations. (We ignore all bias terms for simplicity, and due to the fact that in large neural networks they make no big difference.)\n",
    "\n",
    "\\begin{align}\n",
    "h_t &= \\sigma(\\vect{U}x_t + \\vect{V}h_{t - 1}) && \\mbox{hidden state} \\\\\n",
    "o_t &= \\vect{W}h_t && \\mbox{output score} \\\\\n",
    "\\hat{y}_t &= \\sigma(o_t) && \\mbox{predicted output distribution}\n",
    "\\end{align}\n",
    "\n",
    "The figure at right may be helpful in giving a picture of the RNN computation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a50a6a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "d8a50a6a"
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: open_response_numbering\n",
    "manual: true\n",
    "-->\n",
    "\n",
    "**Question:** To check your understanding, notice that we've defined $\\vect{h}$ so that it has one more element than $\\vect{x}$ and $\\vect{o}$. Why is this?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da38f15",
   "metadata": {},
   "source": "The calculation in each iteration is based on the current hidden state and the previous hidden state. Thus, for the first output we need to add an additional \"prev\" hidden state $h_0$"
  },
  {
   "cell_type": "markdown",
   "id": "1289b72f",
   "metadata": {
    "id": "1289b72f"
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "## Defining the RNN and its input\n",
    "\n",
    "To better understand this process, we set up an example of some RNN parameters and values for $x_1$ and $x_2$ in the next cell, so that you can carry out the RNN operations yourself to calculate $h_1$, $h_2$, $o_1$, and $o_2$. (In this example, the length of the input $N$ is 2, and the dimensionality $dim$ of the $x$, $h$, and $o$ vectors are also 2. Thus, $\\vect{U}$, $\\vect{V}$, and $\\vect{W}$ are all $2\\times 2$ matrices.)"
   ]
  },
  {
   "cell_type": "code",
   "id": "352bffae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T07:28:09.787770Z",
     "iopub.status.busy": "2024-12-09T07:28:09.787558Z",
     "iopub.status.idle": "2024-12-09T07:28:09.793302Z",
     "shell.execute_reply": "2024-12-09T07:28:09.792543Z"
    },
    "id": "352bffae",
    "ExecuteTime": {
     "end_time": "2024-12-11T18:13:45.372406Z",
     "start_time": "2024-12-11T18:13:45.362774Z"
    }
   },
   "source": [
    "# RNN parameters\n",
    "U = torch.Tensor([ [-0.3,  0.6],\n",
    "                   [ 0.2,  0.1] ])\n",
    "V = torch.Tensor([ [ 0.4,  0.4],\n",
    "                   [ 0.9, -0.7] ])\n",
    "W = torch.Tensor([ [ 0.2,  0.1],\n",
    "                   [-0.2,  0.5] ])\n",
    "\n",
    "# inputs\n",
    "x1 = torch.Tensor([0.0, 1.0])\n",
    "x2 = torch.Tensor([0.3, 0.4])\n",
    "\n",
    "# initial value for the hidden state, a zero vector\n",
    "h0 = torch.Tensor([0, 0])\n",
    "\n",
    "# Set which nodes to visualize for later\n",
    "visualized_nodes = [U, V, W, x1, x2, h0]\n",
    "for p in visualized_nodes:\n",
    "    p.requires_grad = True"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "3169a2fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T18:13:45.424565Z",
     "start_time": "2024-12-11T18:13:45.423026Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3f3784ee",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "3f3784ee"
   },
   "source": [
    "## Carrying out a single forward step\n",
    "\n",
    "Given these definitions, calculate values for $h_1$, $h_2$, $o_1$, and $o_2$ using `torch` operations.\n",
    "\n",
    "You may assume for this problem that the nonlinearity $\\sigma$ used in calculating $h_t$ is a Rectified Linear Unit (ReLU), defined by\n",
    "\n",
    "$$\\operatorname{ReLU}(x) = \\max(0, x)$$\n",
    "\n",
    "> ReLU can be implemented as `torch.clamp(x, min=0)`. We've done that for you below.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: forward_by_hand\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "id": "9e2da18b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T07:28:09.796362Z",
     "iopub.status.busy": "2024-12-09T07:28:09.796010Z",
     "iopub.status.idle": "2024-12-09T07:28:09.801214Z",
     "shell.execute_reply": "2024-12-09T07:28:09.800442Z"
    },
    "id": "9e2da18b",
    "ExecuteTime": {
     "end_time": "2024-12-11T18:13:45.453784Z",
     "start_time": "2024-12-11T18:13:45.433083Z"
    }
   },
   "source": [
    "def relu(x):\n",
    "    return torch.clamp(x, min=0)\n",
    "\n",
    "# TODO: calculate h1, h2, o1, and o2 using torch operations\n",
    "h1 = relu(torch.mv(U, x1) + torch.mv(V, h0))\n",
    "o1 = torch.mv(W, h1)\n",
    "h2 = relu(torch.mv(U, x2) + torch.mv(V, h1))\n",
    "o2 = torch.mv(W, h2)"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "f9dce441",
   "metadata": {
    "deletable": false,
    "editable": false,
    "ExecuteTime": {
     "end_time": "2024-12-11T18:13:45.483407Z",
     "start_time": "2024-12-11T18:13:45.465089Z"
    }
   },
   "source": [
    "grader.check(\"forward_by_hand\")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "    All tests passed!\n",
       "    "
      ],
      "text/html": [
       "\n",
       "    \n",
       "    \n",
       "        <p>All tests passed!</p>\n",
       "    \n",
       "    "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "25582e28",
   "metadata": {
    "id": "25582e28"
   },
   "source": [
    "We print out the results for manual verification"
   ]
  },
  {
   "cell_type": "code",
   "id": "63517ab9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-12-09T07:28:09.821247Z",
     "iopub.status.busy": "2024-12-09T07:28:09.821030Z",
     "iopub.status.idle": "2024-12-09T07:28:09.827250Z",
     "shell.execute_reply": "2024-12-09T07:28:09.826513Z"
    },
    "id": "63517ab9",
    "outputId": "fcb503d8-5a51-4646-e944-0f167f8168cb",
    "ExecuteTime": {
     "end_time": "2024-12-11T18:13:45.502818Z",
     "start_time": "2024-12-11T18:13:45.499756Z"
    }
   },
   "source": [
    "print (f\"o1:\\t{o1} \\n\"\n",
    "       f\"o2:\\t{o2}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o1:\ttensor([ 0.1300, -0.0700], grad_fn=<MvBackward0>) \n",
      "o2:\ttensor([0.1430, 0.1990], grad_fn=<MvBackward0>)\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "id": "0178fd11",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Carrying out an arbitrary forward computation\n",
    "\n",
    "Now, let's generalize the forward computation. Define a function `forward` that takes an input (a tensor containing `N` inputs each of dimension `dim`), and the parameters of an RNN (`U`, `V`, and `W`, each of shape `dim x dim`, and returns the final outputs of the model.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: forward_function\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "id": "b19a3d4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T07:28:09.830212Z",
     "iopub.status.busy": "2024-12-09T07:28:09.829796Z",
     "iopub.status.idle": "2024-12-09T07:28:09.834976Z",
     "shell.execute_reply": "2024-12-09T07:28:09.834154Z"
    },
    "ExecuteTime": {
     "end_time": "2024-12-11T18:13:45.527628Z",
     "start_time": "2024-12-11T18:13:45.523749Z"
    }
   },
   "source": [
    "def forward(input, dim, U, V, W):\n",
    "  \"\"\"Performs RNN forward computation of model defined by `U, V, W` \n",
    "     on `input`, returning logits.\n",
    "\n",
    "  Arguments:\n",
    "    input: a tensor containing inputs of shape (N, dim)\n",
    "    dim: dimensionality of input items (\"embeddings\")\n",
    "    U, V, W: tensors for the parameters of the RNN of shape (dim, dim)\n",
    "  Returns:\n",
    "    logits: a tensor of size (N, dim)\n",
    "  \"\"\"\n",
    "  h0 = torch.zeros(dim, device=device)\n",
    "  #TODO: your code below\n",
    "  logits = torch.zeros(len(input), dim)\n",
    "  last_h = h0\n",
    "  for index, x in enumerate(input):\n",
    "    h = relu(torch.mv(U, x) + torch.mv(V, last_h))\n",
    "    o = torch.mv(W, h)\n",
    "\n",
    "    last_h = h\n",
    "    logits[index] = o\n",
    "  return logits"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "e0f0a9a8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "ExecuteTime": {
     "end_time": "2024-12-11T18:13:45.556325Z",
     "start_time": "2024-12-11T18:13:45.546204Z"
    }
   },
   "source": [
    "grader.check(\"forward_function\")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "    All tests passed!\n",
       "    "
      ],
      "text/html": [
       "\n",
       "    \n",
       "    \n",
       "        <p>All tests passed!</p>\n",
       "    \n",
       "    "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "id": "879c4f97",
   "metadata": {},
   "source": [
    "We can verify the forward computation on the example from above."
   ]
  },
  {
   "cell_type": "code",
   "id": "d4cba881",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T07:28:09.869259Z",
     "iopub.status.busy": "2024-12-09T07:28:09.869045Z",
     "iopub.status.idle": "2024-12-09T07:28:09.874912Z",
     "shell.execute_reply": "2024-12-09T07:28:09.874208Z"
    },
    "ExecuteTime": {
     "end_time": "2024-12-11T18:13:45.578022Z",
     "start_time": "2024-12-11T18:13:45.572164Z"
    }
   },
   "source": "forward([x1, x2], 2, U, V, W)\n",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1300, -0.0700],\n",
       "        [ 0.1430,  0.1990]], grad_fn=<CopySlices>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "id": "199eb4e0",
   "metadata": {
    "id": "199eb4e0"
   },
   "source": [
    "## Visualizing the computation graph\n",
    "\n",
    "It can be helpful to visualize the computation graph, that is, the graph of how $o_1$ and $o_2$ are computed from other variables and parameters.\n",
    "\n",
    "> Note that to make the below code work, you need to install `graphviz`:\n",
    ">\n",
    "> * MacOS: `brew install graphviz`\n",
    "> * Deepnote: already installed\n",
    "> * Google Colab: already installed\n",
    "> * Ubuntu: `sudo apt-get install graphviz`\n",
    ">\n",
    "> On Deepnote, the below code might not show anything, but you can check the generated PDF in `computation_graph.pdf`."
   ]
  },
  {
   "cell_type": "code",
   "id": "222095fa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 661
    },
    "execution": {
     "iopub.execute_input": "2024-12-09T07:28:09.878400Z",
     "iopub.status.busy": "2024-12-09T07:28:09.877821Z",
     "iopub.status.idle": "2024-12-09T07:28:10.047267Z",
     "shell.execute_reply": "2024-12-09T07:28:10.046263Z"
    },
    "id": "222095fa",
    "outputId": "e64b1040-e06f-4b73-a38a-7f3aaa28453e",
    "ExecuteTime": {
     "end_time": "2024-12-11T18:13:45.956852Z",
     "start_time": "2024-12-11T18:13:45.648768Z"
    }
   },
   "source": [
    "# Define the mapping from variable name to variable,\n",
    "# so that the nodes in our computation graph can be labeled\n",
    "params = {k: eval(k) for k in ['U', 'V', 'W',\n",
    "                               'x1', 'x2',\n",
    "                               'h0',\n",
    "                               'h1', 'o1',\n",
    "                               'h2', 'o2']}\n",
    "\n",
    "# Visualize the computation graph constructed by PyTorch\n",
    "dot = make_dot((o1, o2), params=params)\n",
    "\n",
    "# Save Graph to `computation_graph.pdf`\n",
    "dot.render(data_dir + 'computation_graph')\n",
    "\n",
    "# Visualize (not working in Deepnote)\n",
    "dot"
   ],
   "outputs": [
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 12.2.1 (20241206.2353)\n -->\n<!-- Pages: 1 -->\n<svg width=\"350pt\" height=\"495pt\"\n viewBox=\"0.00 0.00 350.00 495.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 491)\">\n<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-491 346,-491 346,4 -4,4\"/>\n<!-- 5375990368 -->\n<g id=\"node1\" class=\"node\">\n<title>5375990368</title>\n<polygon fill=\"#caff70\" stroke=\"black\" points=\"132,-239.75 78,-239.75 78,-203.25 132,-203.25 132,-239.75\"/>\n<text text-anchor=\"middle\" x=\"105\" y=\"-224.35\" font-family=\"Times,serif\" font-size=\"12.00\">Mul</text>\n<text text-anchor=\"middle\" x=\"105\" y=\"-210.1\" font-family=\"Times,serif\" font-size=\"12.00\">o1</text>\n</g>\n<!-- 5375991232 -->\n<g id=\"node2\" class=\"node\">\n<title>5375991232</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"104,-305.12 50,-305.12 50,-282.88 104,-282.88 104,-305.12\"/>\n<text text-anchor=\"middle\" x=\"77\" y=\"-289.73\" font-family=\"Times,serif\" font-size=\"12.00\">W</text>\n</g>\n<!-- 5375991232&#45;&gt;5375990368 -->\n<g id=\"edge1\" class=\"edge\">\n<title>5375991232&#45;&gt;5375990368</title>\n<path fill=\"none\" stroke=\"black\" d=\"M81.13,-282.6C84.5,-274.12 89.41,-261.75 93.91,-250.43\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"97.03,-252.05 97.47,-241.46 90.52,-249.47 97.03,-252.05\"/>\n</g>\n<!-- 5375990224 -->\n<g id=\"node11\" class=\"node\">\n<title>5375990224</title>\n<polygon fill=\"#caff70\" stroke=\"black\" points=\"132,-36.5 78,-36.5 78,0 132,0 132,-36.5\"/>\n<text text-anchor=\"middle\" x=\"105\" y=\"-21.1\" font-family=\"Times,serif\" font-size=\"12.00\">Mul</text>\n<text text-anchor=\"middle\" x=\"105\" y=\"-6.85\" font-family=\"Times,serif\" font-size=\"12.00\">o2</text>\n</g>\n<!-- 5375991232&#45;&gt;5375990224 -->\n<g id=\"edge10\" class=\"edge\">\n<title>5375991232&#45;&gt;5375990224</title>\n<path fill=\"none\" stroke=\"black\" d=\"M74.94,-282.44C72.96,-271.74 70.11,-254.67 69,-239.75 63.81,-170.25 83.64,-89.68 95.93,-47.82\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"99.26,-48.88 98.8,-38.29 92.56,-46.86 99.26,-48.88\"/>\n</g>\n<!-- 5375991568 -->\n<g id=\"node3\" class=\"node\">\n<title>5375991568</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"242,-312.25 188,-312.25 188,-275.75 242,-275.75 242,-312.25\"/>\n<text text-anchor=\"middle\" x=\"215\" y=\"-296.85\" font-family=\"Times,serif\" font-size=\"12.00\">Clamp1</text>\n<text text-anchor=\"middle\" x=\"215\" y=\"-282.6\" font-family=\"Times,serif\" font-size=\"12.00\">h1</text>\n</g>\n<!-- 5375991568&#45;&gt;5375990368 -->\n<g id=\"edge2\" class=\"edge\">\n<title>5375991568&#45;&gt;5375990368</title>\n<path fill=\"none\" stroke=\"black\" d=\"M187.53,-275.39C173.64,-266.49 156.6,-255.57 141.62,-245.97\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"143.71,-243.15 133.4,-240.7 139.93,-249.04 143.71,-243.15\"/>\n</g>\n<!-- 5375990032 -->\n<g id=\"node16\" class=\"node\">\n<title>5375990032</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"242,-232.62 188,-232.62 188,-210.38 242,-210.38 242,-232.62\"/>\n<text text-anchor=\"middle\" x=\"215\" y=\"-217.22\" font-family=\"Times,serif\" font-size=\"12.00\">Mul</text>\n</g>\n<!-- 5375991568&#45;&gt;5375990032 -->\n<g id=\"edge18\" class=\"edge\">\n<title>5375991568&#45;&gt;5375990032</title>\n<path fill=\"none\" stroke=\"black\" d=\"M215,-275.57C215,-266.17 215,-254.47 215,-244.45\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"218.5,-244.47 215,-234.47 211.5,-244.47 218.5,-244.47\"/>\n</g>\n<!-- 5375991280 -->\n<g id=\"node4\" class=\"node\">\n<title>5375991280</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"242,-370.5 188,-370.5 188,-348.25 242,-348.25 242,-370.5\"/>\n<text text-anchor=\"middle\" x=\"215\" y=\"-355.1\" font-family=\"Times,serif\" font-size=\"12.00\">Add</text>\n</g>\n<!-- 5375991280&#45;&gt;5375991568 -->\n<g id=\"edge3\" class=\"edge\">\n<title>5375991280&#45;&gt;5375991568</title>\n<path fill=\"none\" stroke=\"black\" d=\"M215,-347.91C215,-341.34 215,-332.51 215,-323.94\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"218.5,-324.19 215,-314.19 211.5,-324.19 218.5,-324.19\"/>\n</g>\n<!-- 5375989984 -->\n<g id=\"node5\" class=\"node\">\n<title>5375989984</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"198,-428.75 144,-428.75 144,-406.5 198,-406.5 198,-428.75\"/>\n<text text-anchor=\"middle\" x=\"171\" y=\"-413.35\" font-family=\"Times,serif\" font-size=\"12.00\">Mul</text>\n</g>\n<!-- 5375989984&#45;&gt;5375991280 -->\n<g id=\"edge4\" class=\"edge\">\n<title>5375989984&#45;&gt;5375991280</title>\n<path fill=\"none\" stroke=\"black\" d=\"M179.28,-406.04C185.05,-398.66 192.93,-388.59 199.82,-379.78\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"202.42,-382.13 205.83,-372.1 196.91,-377.82 202.42,-382.13\"/>\n</g>\n<!-- 5375991424 -->\n<g id=\"node6\" class=\"node\">\n<title>5375991424</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"126,-487 72,-487 72,-464.75 126,-464.75 126,-487\"/>\n<text text-anchor=\"middle\" x=\"99\" y=\"-471.6\" font-family=\"Times,serif\" font-size=\"12.00\">U</text>\n</g>\n<!-- 5375991424&#45;&gt;5375989984 -->\n<g id=\"edge5\" class=\"edge\">\n<title>5375991424&#45;&gt;5375989984</title>\n<path fill=\"none\" stroke=\"black\" d=\"M112.54,-464.29C122.7,-456.36 136.83,-445.32 148.65,-436.09\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"150.6,-439 156.33,-430.09 146.29,-433.49 150.6,-439\"/>\n</g>\n<!-- 5375991088 -->\n<g id=\"node14\" class=\"node\">\n<title>5375991088</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"126,-428.75 72,-428.75 72,-406.5 126,-406.5 126,-428.75\"/>\n<text text-anchor=\"middle\" x=\"99\" y=\"-413.35\" font-family=\"Times,serif\" font-size=\"12.00\">Mul</text>\n</g>\n<!-- 5375991424&#45;&gt;5375991088 -->\n<g id=\"edge14\" class=\"edge\">\n<title>5375991424&#45;&gt;5375991088</title>\n<path fill=\"none\" stroke=\"black\" d=\"M99,-464.29C99,-457.62 99,-448.74 99,-440.59\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"102.5,-440.67 99,-430.67 95.5,-440.67 102.5,-440.67\"/>\n</g>\n<!-- 5375991376 -->\n<g id=\"node7\" class=\"node\">\n<title>5375991376</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"198,-487 144,-487 144,-464.75 198,-464.75 198,-487\"/>\n<text text-anchor=\"middle\" x=\"171\" y=\"-471.6\" font-family=\"Times,serif\" font-size=\"12.00\">x1</text>\n</g>\n<!-- 5375991376&#45;&gt;5375989984 -->\n<g id=\"edge6\" class=\"edge\">\n<title>5375991376&#45;&gt;5375989984</title>\n<path fill=\"none\" stroke=\"black\" d=\"M171,-464.29C171,-457.62 171,-448.74 171,-440.59\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"174.5,-440.67 171,-430.67 167.5,-440.67 174.5,-440.67\"/>\n</g>\n<!-- 5375990992 -->\n<g id=\"node8\" class=\"node\">\n<title>5375990992</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"270,-428.75 216,-428.75 216,-406.5 270,-406.5 270,-428.75\"/>\n<text text-anchor=\"middle\" x=\"243\" y=\"-413.35\" font-family=\"Times,serif\" font-size=\"12.00\">Mul</text>\n</g>\n<!-- 5375990992&#45;&gt;5375991280 -->\n<g id=\"edge7\" class=\"edge\">\n<title>5375990992&#45;&gt;5375991280</title>\n<path fill=\"none\" stroke=\"black\" d=\"M237.73,-406.04C234.25,-399.05 229.57,-389.65 225.36,-381.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"228.51,-379.66 220.92,-372.26 222.24,-382.77 228.51,-379.66\"/>\n</g>\n<!-- 5375991472 -->\n<g id=\"node9\" class=\"node\">\n<title>5375991472</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"342,-487 288,-487 288,-464.75 342,-464.75 342,-487\"/>\n<text text-anchor=\"middle\" x=\"315\" y=\"-471.6\" font-family=\"Times,serif\" font-size=\"12.00\">V</text>\n</g>\n<!-- 5375991472&#45;&gt;5375990992 -->\n<g id=\"edge8\" class=\"edge\">\n<title>5375991472&#45;&gt;5375990992</title>\n<path fill=\"none\" stroke=\"black\" d=\"M301.46,-464.29C291.3,-456.36 277.17,-445.32 265.35,-436.09\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"267.71,-433.49 257.67,-430.09 263.4,-439 267.71,-433.49\"/>\n</g>\n<!-- 5375991472&#45;&gt;5375990032 -->\n<g id=\"edge17\" class=\"edge\">\n<title>5375991472&#45;&gt;5375990032</title>\n<path fill=\"none\" stroke=\"black\" d=\"M312.77,-464.54C306.05,-434.39 284.36,-344.32 251,-275.75 245.28,-263.98 237.24,-251.82 230.22,-242.1\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"233.09,-240.1 224.3,-234.18 227.48,-244.29 233.09,-240.1\"/>\n</g>\n<!-- 5375991712 -->\n<g id=\"node10\" class=\"node\">\n<title>5375991712</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"270,-487 216,-487 216,-464.75 270,-464.75 270,-487\"/>\n<text text-anchor=\"middle\" x=\"243\" y=\"-471.6\" font-family=\"Times,serif\" font-size=\"12.00\">h0</text>\n</g>\n<!-- 5375991712&#45;&gt;5375990992 -->\n<g id=\"edge9\" class=\"edge\">\n<title>5375991712&#45;&gt;5375990992</title>\n<path fill=\"none\" stroke=\"black\" d=\"M243,-464.29C243,-457.62 243,-448.74 243,-440.59\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"246.5,-440.67 243,-430.67 239.5,-440.67 246.5,-440.67\"/>\n</g>\n<!-- 5375990080 -->\n<g id=\"node12\" class=\"node\">\n<title>5375990080</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"160,-109 106,-109 106,-72.5 160,-72.5 160,-109\"/>\n<text text-anchor=\"middle\" x=\"133\" y=\"-93.6\" font-family=\"Times,serif\" font-size=\"12.00\">Clamp1</text>\n<text text-anchor=\"middle\" x=\"133\" y=\"-79.35\" font-family=\"Times,serif\" font-size=\"12.00\">h2</text>\n</g>\n<!-- 5375990080&#45;&gt;5375990224 -->\n<g id=\"edge11\" class=\"edge\">\n<title>5375990080&#45;&gt;5375990224</title>\n<path fill=\"none\" stroke=\"black\" d=\"M126.08,-72.32C123.11,-64.84 119.56,-55.9 116.22,-47.51\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"119.54,-46.37 112.59,-38.37 113.03,-48.96 119.54,-46.37\"/>\n</g>\n<!-- 5375991136 -->\n<g id=\"node13\" class=\"node\">\n<title>5375991136</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"187,-167.25 133,-167.25 133,-145 187,-145 187,-167.25\"/>\n<text text-anchor=\"middle\" x=\"160\" y=\"-151.85\" font-family=\"Times,serif\" font-size=\"12.00\">Add</text>\n</g>\n<!-- 5375991136&#45;&gt;5375990080 -->\n<g id=\"edge12\" class=\"edge\">\n<title>5375991136&#45;&gt;5375990080</title>\n<path fill=\"none\" stroke=\"black\" d=\"M155.54,-144.66C152.65,-137.86 148.72,-128.65 144.96,-119.82\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"148.26,-118.65 141.12,-110.82 141.82,-121.39 148.26,-118.65\"/>\n</g>\n<!-- 5375991088&#45;&gt;5375991136 -->\n<g id=\"edge13\" class=\"edge\">\n<title>5375991088&#45;&gt;5375991136</title>\n<path fill=\"none\" stroke=\"black\" d=\"M101.49,-406.26C108.02,-379.01 126.2,-303.06 141,-239.75 145.88,-218.87 151.36,-195.01 155.17,-178.31\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"158.47,-179.57 157.29,-169.04 151.65,-178.01 158.47,-179.57\"/>\n</g>\n<!-- 5375990944 -->\n<g id=\"node15\" class=\"node\">\n<title>5375990944</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"54,-487 0,-487 0,-464.75 54,-464.75 54,-487\"/>\n<text text-anchor=\"middle\" x=\"27\" y=\"-471.6\" font-family=\"Times,serif\" font-size=\"12.00\">x2</text>\n</g>\n<!-- 5375990944&#45;&gt;5375991088 -->\n<g id=\"edge15\" class=\"edge\">\n<title>5375990944&#45;&gt;5375991088</title>\n<path fill=\"none\" stroke=\"black\" d=\"M40.54,-464.29C50.7,-456.36 64.83,-445.32 76.65,-436.09\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"78.6,-439 84.33,-430.09 74.29,-433.49 78.6,-439\"/>\n</g>\n<!-- 5375990032&#45;&gt;5375991136 -->\n<g id=\"edge16\" class=\"edge\">\n<title>5375990032&#45;&gt;5375991136</title>\n<path fill=\"none\" stroke=\"black\" d=\"M205.92,-210.03C197.91,-200.81 186.04,-187.13 176.38,-176\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"179.1,-173.8 169.91,-168.54 173.82,-178.38 179.1,-173.8\"/>\n</g>\n</g>\n</svg>\n",
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x1406f1c70>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "id": "7cf7bcdc",
   "metadata": {
    "id": "7cf7bcdc"
   },
   "source": [
    "Is the generated computation graph what you expected?\n",
    "\n",
    "Before continuing our exploration of the RNN caculations for the backward step, we go through a couple of applications of RNNs. We'll come back to finish the backward step calculations in some detail after the applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a5340c",
   "metadata": {
    "id": "09a5340c"
   },
   "source": [
    "# Application: Expressing bigram language models as RNNs\n",
    "\n",
    "In this section, as an exercise in understanding how RNNs work, you'll design an RNN to behave like a bigram model. By providing a reduction from bigram models to RNNs, you thereby show that RNNs are (not surprisingly) more expressive than bigram language models.\n",
    "\n",
    "## Bigram language models\n",
    "\n",
    "Recall that a bigram language model uses the previous word to predict the next word in a sequence $w_1 \\cdots w_N$. A bigram model over a vocabulary $\\vect{v} = \\{v_1, \\ldots, v_V\\}$ is specified by a set of probabilities $\\Prob(w_{t+1} = v_j \\given w_t = v_i)$, the probability that a word of type $v_j$ follows a word of type $v_i$.\n",
    "(As usual, we'll abbreviate this probability $\\Prob(v_j \\given v_i)$, since the probability is assumed to be the same for all $t$.)\n",
    "\n",
    "We can pack these probabilities into a single table $T$ with $V$ rows and $V$ columns such that  \n",
    "\n",
    "$$T_{ij} = \\Prob(v_j \\given v_i)$$\n",
    "\n",
    "Importantly, the sum $\\sum_{j=1}^{V} T_{ij}$ is $1$ for all $i$. The vector $T_i$ (the $i$-th row of table $T$) thus constitutes the probability distribution for the word following $v_i$.\n",
    "\n",
    "For this activity, we use a vocabulary with only two tokens (we can think of them as $a$ and $b$) encoded as one-hot vectors ($v_1=$ `[1,0]` and $v_2=$  `[0,1]`) and we provide a transition table $T$. We also define two sample sequences representing $aaaaaabbaa$ and $babbbbabbb$."
   ]
  },
  {
   "cell_type": "code",
   "id": "3f76d937",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T07:28:10.050882Z",
     "iopub.status.busy": "2024-12-09T07:28:10.050296Z",
     "iopub.status.idle": "2024-12-09T07:28:10.056372Z",
     "shell.execute_reply": "2024-12-09T07:28:10.055533Z"
    },
    "id": "3f76d937",
    "ExecuteTime": {
     "end_time": "2024-12-11T18:13:45.979461Z",
     "start_time": "2024-12-11T18:13:45.975242Z"
    }
   },
   "source": [
    "# the vocabulary V\n",
    "Vocab = torch.Tensor([ [1, 0],\n",
    "                       [0, 1] ])\n",
    "\n",
    "# the bigram probabilities T_ij\n",
    "T = torch.Tensor([ [0.6, 0.4],\n",
    "                   [0.3, 0.7] ])\n",
    "\n",
    "# two sample sequences\n",
    "seq1 = torch.Tensor(\n",
    "    [ [1,0], [1,0], [1,0], [1,0], [1,0], [1,0], [0,1], [0,1], [1,0], [1,0] ])\n",
    "seq2 = torch.Tensor(\n",
    "    [ [0,1], [1,0], [0,1], [0,1], [0,1], [0,1], [1,0], [0,1], [0,1], [0,1] ])"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "4e14534a"
   },
   "cell_type": "markdown",
   "source": [
    "Before proceeding, take a guess as to which of the two sequences would be more likely according to the provided bigram model. (We won't hold you to the guess.)\n",
    "\n",
    "Now write a function `sequence_probability` to find the probability of a sequence according to the bigram model. Below, we'll use that function to check your guess.\n",
    "\n",
    "> As in the previous lab, we'll ignore the contribution of the first $n-1$ tokens (the first token in the case of this example), since it doesn't have sufficient context. In a full $n$-gram model, we'd pad the start of the string with $n-1$ \"start of sequence\" tokens that are not part of the main vocabulary and have probability 1. It's standard also to add an \"end of sequence\" token at the end as well. But we'll pass on these niceties for now, if for no other reason than that it would double the size of the vocabulary you'd have to deal with.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: bigram\n",
    "-->"
   ],
   "id": "4e14534a"
  },
  {
   "cell_type": "code",
   "id": "e2bc45e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T07:28:10.060009Z",
     "iopub.status.busy": "2024-12-09T07:28:10.059408Z",
     "iopub.status.idle": "2024-12-09T07:28:10.064757Z",
     "shell.execute_reply": "2024-12-09T07:28:10.063883Z"
    },
    "id": "e2bc45e4",
    "ExecuteTime": {
     "end_time": "2024-12-11T18:13:45.986493Z",
     "start_time": "2024-12-11T18:13:45.983842Z"
    }
   },
   "source": [
    "# TODO -- Write a function to find the probability of a sequence given a bigram table\n",
    "def sequence_probability(seq, T):\n",
    "    \"\"\"Returns the probability of a sequence `seq` under a bigram table `T`.\n",
    "    Arguments:\n",
    "      seq: a sequence of size N x vocab_size, where seq[i] is the one-hot\n",
    "           representation for the i-th word.\n",
    "      T: a bigram table, where T_{ij} = P(v_j | v_i).\n",
    "    Returns: the probability of the sequence, a tensor of a single element.\"\"\"\n",
    "    prob = 1\n",
    "    for index in range(len(seq)-1):\n",
    "        i = torch.argmax(seq[index])\n",
    "        j = torch.argmax(seq[index+1])\n",
    "        prob *= T[i][j]\n",
    "    return prob\n"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "6f8bc73f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "ExecuteTime": {
     "end_time": "2024-12-11T18:13:46.008050Z",
     "start_time": "2024-12-11T18:13:45.998228Z"
    }
   },
   "source": [
    "grader.check(\"bigram\")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "    All tests passed!\n",
       "    "
      ],
      "text/html": [
       "\n",
       "    \n",
       "    \n",
       "        <p>All tests passed!</p>\n",
       "    \n",
       "    "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "id": "28c870e4",
   "metadata": {
    "id": "28c870e4"
   },
   "source": [
    "We can use the `sequence_probability` function to find the probabilities of the two sequences."
   ]
  },
  {
   "cell_type": "code",
   "id": "fc8f1efc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-12-09T07:28:10.101486Z",
     "iopub.status.busy": "2024-12-09T07:28:10.101266Z",
     "iopub.status.idle": "2024-12-09T07:28:10.105705Z",
     "shell.execute_reply": "2024-12-09T07:28:10.104839Z"
    },
    "id": "fc8f1efc",
    "outputId": "7d84cab5-6f3e-491d-d24e-fbd60eea180f",
    "ExecuteTime": {
     "end_time": "2024-12-11T18:13:46.024026Z",
     "start_time": "2024-12-11T18:13:46.020041Z"
    }
   },
   "source": [
    "print(f\"Probability of A: {sequence_probability(seq1, T):.5f}\\n\"\n",
    "      f\"Probability of B: {sequence_probability(seq2, T):.5f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of A: 0.00392\n",
      "Probability of B: 0.00242\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "id": "8e46b653",
   "metadata": {
    "id": "8e46b653"
   },
   "source": [
    "Was your guess correct?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a290fb9c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "a290fb9c"
   },
   "source": [
    "## Tiny bigram RNN\n",
    "\n",
    "In theory, given enough capacity, [an RNN can approximate any function arbitrarily well](https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.16.7590&rep=rep1&type=pdf). (In practice, we don't have infinite capacity, and even if we did have sufficient capacity, that doesn't mean that a particular optimization method, like stochastic gradient descent as you've been using in project segment 1, can find the global optimum.)\n",
    "\n",
    "In this section, you'll show that an RNN is at least as expressive as a bigram language model. You'll design the activation function $\\sigma$ and the parameters $\\vect{U}$, $\\vect{V}$, and $\\vect{W}$ of an RNN such that it behaves exactly like the particular bigram model above, by taking as input a sequence of one-hot representations of words, and outputting at each step a vector with the probabilities of the next word.\n",
    "\n",
    "For instance, the probabilities for the word following $v_i$ should be $T_i$, the row from the transition matrix. Given a sequence beginning with $v_1$, represented by the one-hot encoding [1, 0], your RNN's first output should be\n",
    "\n",
    "$$ o_1 = \\vect{W}h_1= \\vect{W} \\sigma\\left(\\vect{U} \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}\n",
    "                            + \\vect{V} h_0\n",
    "                            \\right)\n",
    "       = T_1 $$\n",
    "\n",
    "etc. Assume that $h_0$, the initial $h$ value, is $\\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}$.\n",
    "\n",
    "> Hint 1: Use $\\sigma(x) = x$ for simplicity.\n",
    ">\n",
    "> Hint 2: You're going to want to work this out on paper before filling in your solution in the next cell.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: tiny_bigram_RNN\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "id": "a9fe7bc2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T07:28:10.108744Z",
     "iopub.status.busy": "2024-12-09T07:28:10.108527Z",
     "iopub.status.idle": "2024-12-09T07:28:10.112673Z",
     "shell.execute_reply": "2024-12-09T07:28:10.111919Z"
    },
    "id": "a9fe7bc2",
    "ExecuteTime": {
     "end_time": "2024-12-11T18:13:46.045558Z",
     "start_time": "2024-12-11T18:13:46.042278Z"
    }
   },
   "source": [
    "#TODO -- Define the parameters of the model in terms of the bigram probability matrix `T` and other constants\n",
    "h0 = torch.zeros(2)\n",
    "sigma = lambda x: x\n",
    "U = torch.tensor([[0.6, 0.3], [0.4, 0.7]], dtype=torch.float32)\n",
    "V = torch.tensor([[0, 0], [0, 0]], dtype=torch.float32)\n",
    "W = torch.tensor([[1, 0], [0, 1]], dtype=torch.float32)"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "id": "38c50cf9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "ExecuteTime": {
     "end_time": "2024-12-11T18:13:46.086708Z",
     "start_time": "2024-12-11T18:13:46.069437Z"
    }
   },
   "source": [
    "grader.check(\"tiny_bigram_RNN\")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "    All tests passed!\n",
       "    "
      ],
      "text/html": [
       "\n",
       "    \n",
       "    \n",
       "        <p>All tests passed!</p>\n",
       "    \n",
       "    "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "id": "26839ddb",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "26839ddb"
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## General bigram RNN\n",
    "\n",
    "Above, you worked out the solution for implementing a bigram model for a two-word vocabulary as an RNN. But the construction can be generalized for bigram models over vocabularies of arbitrary size, say, $N$ word types.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: open_response_bigram\n",
    "manual: true\n",
    "-->\n",
    "\n",
    "**Question:**\n",
    "In general, given an $N \\times N$ bigram probability matrix $T_{ij}$ what would be the activation function $\\sigma$ and the parameters $\\vect{U}$, $\\vect{V}$, and $\\vect{W}$,  of an RNN that outputs $T_i$ given $v_i$ as an input?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d782323e",
   "metadata": {},
   "source": [
    "We can generalize what we did with the $2\\times2$ to $N \\times N$ with the matrices $\\vect{V} = 0$\n",
    "$\\vect{U} = T^T$ $\\vect{W} = I$ and the identity activation function $\\sigma(x)=x$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6549f162",
   "metadata": {
    "id": "6549f162"
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "#  RNN calculations by hand – the backward step\n",
    "\n",
    "We return to the exercise of carrying out the calculations for RNNs, this time for the backward step. The remainder of the lab needs you to take some derivatives. In these exercises you will both build your intuition and gain a concrete understanding of how back-propagation works in an RNN.\n",
    "\n",
    "Back-propagation is the method used to compute the gradients of an RNN. First, the RNN runs forward on some inputs, and then we calculate the loss as a function of the output (a measure of how far off the RNN's output $o_t$ was from the desired output $y_t$). The loss function we will be using is the squared error:\n",
    "\n",
    "$$ L = \\sum_{t = 1}^{N} (y_{t} - o_{t})^2 $$\n",
    "\n",
    "For the particular case of a language model, the \"desired output\" is just the next word in the sequence, so we have\n",
    "\n",
    "$$ L = \\sum_{t = 1}^{N} (x_{t+1} - o_{t})^2 $$\n",
    "\n",
    "> There's a little issue with the last step, since $x_{N+1}$ doesn't exist. Let's pretend that $x_{N+1}$ exists below for brevity of notations. (See the comment above about end-of-sequence tokens.)\n",
    "\n",
    "> Note that we use squared error loss here mainly for simplicity. In real language modeling tasks people use cross entropy loss, which you've seen in project segment 1.\n",
    "\n",
    "We then find the derivatives of the loss with respect to each parameter and use the derivatives to make small adjustments to the parameters to reduce the loss. This process is repeated until the loss is minimized.\n",
    "\n",
    "To minimize the loss function, we need to calculate the derivative of the loss $L$ with respect to all parameters. In this lab, we only consider how to calculate the derivative of $L$ with respect to $\\vect{U}$, but other parameters work similarly.\n",
    "\n",
    "For simplicity, let's assume for now that $h_0, \\ldots, h_N$, $x_1, \\ldots, x_N$ and $o_1, \\ldots, o_N$ are all scalars. Therefore, the parameters $\\vect{U}$, $\\vect{V}$, $\\vect{W}$ are all scalars as well. Such an assumption avoids taking gradients of vectors and matrices, although the below results can be easily generalized.\n",
    "\n",
    "In the next few subsections, you'll derive the gradient formulas for RNNs operating on sequences first of length 1, then 2, then 3, and finally on arbitrary length sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cb9b11",
   "metadata": {
    "id": "e3cb9b11"
   },
   "source": [
    "## RNN backprop on very very short sequences\n",
    "\n",
    "Consider an RNN run on an input sequence of length 1. This RNN's output sequence will therefore consist only of a single output $o_1$.\n",
    "\n",
    "As you can see from the loss function given above, $L = (x_2 - o_1)^2$ is a function of $o_1$ and $x_2$, therefore we can find\n",
    "\n",
    "$$\\frac{\\partial L(o_1, x_2)}{\\partial o_1} = 2(o_1 - x_2)$$\n",
    "\n",
    "Furthermore, $o_1$ is a function of $h_1$ and $\\vect{W}$, so we can find $\\frac{\\partial o_1(h_1, \\vect{W})}{\\partial h_1}$. Finally, $h_1$ is a function of $\\vect{U}$, $\\vect{V}$, $h_0$, and $x_1$, so we can find $\\frac{\\partial h_1(\\vect{U}, \\vect{V}, h_0, x_1)}{\\partial \\vect{U}}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a61f1b4",
   "metadata": {
    "id": "6a61f1b4"
   },
   "source": [
    "First, let's visualize the computation graph for more intuition. Note that different from the previous computation graph, we only show the variables that we are interested in."
   ]
  },
  {
   "cell_type": "code",
   "id": "fe30b73f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 568
    },
    "execution": {
     "iopub.execute_input": "2024-12-09T07:28:10.134507Z",
     "iopub.status.busy": "2024-12-09T07:28:10.134295Z",
     "iopub.status.idle": "2024-12-09T07:28:10.203165Z",
     "shell.execute_reply": "2024-12-09T07:28:10.202178Z"
    },
    "id": "fe30b73f",
    "outputId": "e6f351ad-60c3-424e-afae-f7edd362ea88",
    "ExecuteTime": {
     "end_time": "2024-12-11T18:13:46.237373Z",
     "start_time": "2024-12-11T18:13:46.101145Z"
    }
   },
   "source": [
    "# RNN parameters\n",
    "U_ = torch.Tensor([0.1]) # we use U_ instead of U (etc.) to avoid autograding issues\n",
    "V_ = torch.Tensor([0.2])\n",
    "W_ = torch.Tensor([0.3])\n",
    "\n",
    "# inputs\n",
    "x1_ = torch.Tensor([0.5])\n",
    "x2_ = torch.Tensor([0.6])\n",
    "x3_ = torch.Tensor([0.7])\n",
    "\n",
    "# initial value for the hidden state, a zero vector\n",
    "h0_ = torch.Tensor([0])\n",
    "\n",
    "# Set which nodes to visualize later\n",
    "visualized_nodes = [U_, ]\n",
    "for p in visualized_nodes:\n",
    "    p.requires_grad = True\n",
    "\n",
    "# Calculate h1, o1\n",
    "h1_ = relu(U_ * x1_ + V_ * h0_)\n",
    "o1_ = W_ * h1_\n",
    "\n",
    "L_ = (o1_ - x2_) ** 2\n",
    "\n",
    "params = {k: eval(k+'_') for k in ['L', 'U', 'h1', 'o1']}\n",
    "dot = make_dot(L_, params=params)\n",
    "# Save Graph to `computation_graph_1.pdf`\n",
    "dot.render(data_dir + 'computation_graph_1')\n",
    "dot"
   ],
   "outputs": [
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 12.2.1 (20241206.2353)\n -->\n<!-- Pages: 1 -->\n<svg width=\"62pt\" height=\"423pt\"\n viewBox=\"0.00 0.00 62.00 422.50\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 418.5)\">\n<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-418.5 58,-418.5 58,4 -4,4\"/>\n<!-- 5000618480 -->\n<g id=\"node1\" class=\"node\">\n<title>5000618480</title>\n<polygon fill=\"#caff70\" stroke=\"black\" points=\"54,-36.5 0,-36.5 0,0 54,0 54,-36.5\"/>\n<text text-anchor=\"middle\" x=\"27\" y=\"-21.1\" font-family=\"Times,serif\" font-size=\"12.00\">Pow</text>\n<text text-anchor=\"middle\" x=\"27\" y=\"-6.85\" font-family=\"Times,serif\" font-size=\"12.00\">L</text>\n</g>\n<!-- 4999830352 -->\n<g id=\"node2\" class=\"node\">\n<title>4999830352</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"54,-94.75 0,-94.75 0,-72.5 54,-72.5 54,-94.75\"/>\n<text text-anchor=\"middle\" x=\"27\" y=\"-79.35\" font-family=\"Times,serif\" font-size=\"12.00\">Sub</text>\n</g>\n<!-- 4999830352&#45;&gt;5000618480 -->\n<g id=\"edge1\" class=\"edge\">\n<title>4999830352&#45;&gt;5000618480</title>\n<path fill=\"none\" stroke=\"black\" d=\"M27,-72.16C27,-65.59 27,-56.76 27,-48.19\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"30.5,-48.44 27,-38.44 23.5,-48.44 30.5,-48.44\"/>\n</g>\n<!-- 4999831456 -->\n<g id=\"node3\" class=\"node\">\n<title>4999831456</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"54,-167.25 0,-167.25 0,-130.75 54,-130.75 54,-167.25\"/>\n<text text-anchor=\"middle\" x=\"27\" y=\"-151.85\" font-family=\"Times,serif\" font-size=\"12.00\">Mul</text>\n<text text-anchor=\"middle\" x=\"27\" y=\"-137.6\" font-family=\"Times,serif\" font-size=\"12.00\">o1</text>\n</g>\n<!-- 4999831456&#45;&gt;4999830352 -->\n<g id=\"edge2\" class=\"edge\">\n<title>4999831456&#45;&gt;4999830352</title>\n<path fill=\"none\" stroke=\"black\" d=\"M27,-130.35C27,-123.03 27,-114.47 27,-106.74\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"30.5,-106.76 27,-96.76 23.5,-106.76 30.5,-106.76\"/>\n</g>\n<!-- 5000618384 -->\n<g id=\"node4\" class=\"node\">\n<title>5000618384</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"54,-239.75 0,-239.75 0,-203.25 54,-203.25 54,-239.75\"/>\n<text text-anchor=\"middle\" x=\"27\" y=\"-224.35\" font-family=\"Times,serif\" font-size=\"12.00\">Clamp1</text>\n<text text-anchor=\"middle\" x=\"27\" y=\"-210.1\" font-family=\"Times,serif\" font-size=\"12.00\">h1</text>\n</g>\n<!-- 5000618384&#45;&gt;4999831456 -->\n<g id=\"edge3\" class=\"edge\">\n<title>5000618384&#45;&gt;4999831456</title>\n<path fill=\"none\" stroke=\"black\" d=\"M27,-203.07C27,-195.84 27,-187.25 27,-179.11\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"30.5,-179.23 27,-169.23 23.5,-179.23 30.5,-179.23\"/>\n</g>\n<!-- 4550484512 -->\n<g id=\"node5\" class=\"node\">\n<title>4550484512</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"54,-298 0,-298 0,-275.75 54,-275.75 54,-298\"/>\n<text text-anchor=\"middle\" x=\"27\" y=\"-282.6\" font-family=\"Times,serif\" font-size=\"12.00\">Add</text>\n</g>\n<!-- 4550484512&#45;&gt;5000618384 -->\n<g id=\"edge4\" class=\"edge\">\n<title>4550484512&#45;&gt;5000618384</title>\n<path fill=\"none\" stroke=\"black\" d=\"M27,-275.41C27,-268.84 27,-260.01 27,-251.44\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"30.5,-251.69 27,-241.69 23.5,-251.69 30.5,-251.69\"/>\n</g>\n<!-- 5374571376 -->\n<g id=\"node6\" class=\"node\">\n<title>5374571376</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"54,-356.25 0,-356.25 0,-334 54,-334 54,-356.25\"/>\n<text text-anchor=\"middle\" x=\"27\" y=\"-340.85\" font-family=\"Times,serif\" font-size=\"12.00\">Mul</text>\n</g>\n<!-- 5374571376&#45;&gt;4550484512 -->\n<g id=\"edge5\" class=\"edge\">\n<title>5374571376&#45;&gt;4550484512</title>\n<path fill=\"none\" stroke=\"black\" d=\"M27,-333.54C27,-326.87 27,-317.99 27,-309.84\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"30.5,-309.92 27,-299.92 23.5,-309.92 30.5,-309.92\"/>\n</g>\n<!-- 5374573584 -->\n<g id=\"node7\" class=\"node\">\n<title>5374573584</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"54,-414.5 0,-414.5 0,-392.25 54,-392.25 54,-414.5\"/>\n<text text-anchor=\"middle\" x=\"27\" y=\"-399.1\" font-family=\"Times,serif\" font-size=\"12.00\">U</text>\n</g>\n<!-- 5374573584&#45;&gt;5374571376 -->\n<g id=\"edge6\" class=\"edge\">\n<title>5374573584&#45;&gt;5374571376</title>\n<path fill=\"none\" stroke=\"black\" d=\"M27,-391.79C27,-385.12 27,-376.24 27,-368.09\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"30.5,-368.17 27,-358.17 23.5,-368.17 30.5,-368.17\"/>\n</g>\n</g>\n</svg>\n",
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x12a035ee0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "id": "55a8fefd",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "55a8fefd"
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question:** Find a formula for $\\frac{\\partial L(\\vect{U}, \\vect{V}, \\vect{W}, x_1, x_2, h_0)}{\\partial \\vect{U}}$ in terms of $\\frac{\\partial L(o_1, x_2)}{\\partial o_1}$, $\\frac{\\partial o_1(\\vect{W}, h_1)}{\\partial h_1}$ ,and $\\frac{\\partial h_1(\\vect{U}, \\vect{V}, h_0, x_1)}{\\partial \\vect{U}}$. You might find the above computation graph useful: how does $L$ depend on $\\vect{U}$?\n",
    "\n",
    ">Note that in your answer you can omit the arguments of the functions for brevity (e.g., you can use $\\frac{\\partial L}{\\partial o_1}$ instead of $\\frac{\\partial L(o_1, x_2)}{\\partial o_1}$), but keep in mind that the arguments are important: e.g., $o_1$ eventually depends on $\\vect{U}$, so $\\frac{\\partial o_1(\\vect{U}, \\vect{V}, \\vect{W}, x_1, x_2, h_0)}{\\partial \\vect{U}}$ is likely not zero, but if instead we assume its arguments are $h_1$ and $\\vect{W}$, i.e., $o_1 = o_1(h_1, \\vect{W})$, then $\\frac{\\partial o_1}{\\partial U}$ is undefined or 0, as when we take partial derivatives, we hold other arguments ($h_1$ and $\\vect{W}$ in this case) as constant.\n",
    "\n",
    ">Hint: Use the chain rule.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: open_response_backprop1\n",
    "manual: true\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823de2df",
   "metadata": {},
   "source": [
    "$o_1 = \\vect{W}h_1 = \\vect{W}\\sigma (\\vect{U}x_1 + \\vect{V}h_0)$\n",
    "\n",
    "$L = (x_2 - o_1)^2 = (x_2 - \\vect{W}\\sigma (\\vect{U}x_1 + \\vect{V}h_0))^2 $\n",
    "\n",
    "$\\frac{\\partial L(\\vect{U}, \\vect{V}, \\vect{W}, x_1, x_2, h_0)}{\\partial \\vect{U}}$\n",
    "$ = (\\frac{\\partial L(o_1, x_2)}{\\partial o_1})(\\frac{\\partial o_1(\\vect{W}, h_1)}{\\partial h_1}) (\\frac{\\partial h_1(\\vect{U}, \\vect{V}, h_0, x_1)}{\\partial \\vect{U}}) $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af545f16",
   "metadata": {
    "id": "af545f16"
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "## RNN backprop on very short sequences\n",
    "\n",
    "Consider an RNN run on an input sequence of length 2. This RNN's output sequence $o$ will consist of $o_1$ and $o_2$ and the loss will be\n",
    "\n",
    "$$ L = (x_2 - o_1)^2 + (x_3 - o_2)^2 $$\n",
    "\n",
    "Let's visualize the computation graph."
   ]
  },
  {
   "cell_type": "code",
   "id": "21478791",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 906
    },
    "execution": {
     "iopub.execute_input": "2024-12-09T07:28:10.206894Z",
     "iopub.status.busy": "2024-12-09T07:28:10.206275Z",
     "iopub.status.idle": "2024-12-09T07:28:10.276060Z",
     "shell.execute_reply": "2024-12-09T07:28:10.275060Z"
    },
    "id": "21478791",
    "outputId": "8fdee509-500a-4e98-8f69-088e24e14a18",
    "ExecuteTime": {
     "end_time": "2024-12-11T18:13:46.394717Z",
     "start_time": "2024-12-11T18:13:46.255789Z"
    }
   },
   "source": [
    "# RNN parameters\n",
    "U_ = torch.Tensor([0.1])\n",
    "V_ = torch.Tensor([0.2])\n",
    "W_ = torch.Tensor([0.3])\n",
    "\n",
    "# inputs\n",
    "x1_ = torch.Tensor([0.5])\n",
    "x2_ = torch.Tensor([0.6])\n",
    "x3_ = torch.Tensor([0.7])\n",
    "\n",
    "# initial value for the hidden state, a zero vector\n",
    "h0_ = torch.Tensor([0])\n",
    "\n",
    "# Set which nodes to visualize later\n",
    "visualized_nodes = [U_, ]\n",
    "for p in visualized_nodes:\n",
    "    p.requires_grad = True\n",
    "\n",
    "# Calculate h1, o1\n",
    "h1_ = relu(U_ * x1_ + V_ * h0_)\n",
    "h2_ = relu(U_ * x2_ + V_ * h1_)\n",
    "o2_ = W_ * h2_\n",
    "o1_ = W_ * h1_\n",
    "\n",
    "L_ = (o1_ - x2_)**2 + (o2_ - x3_)**2\n",
    "\n",
    "params = {k: eval(k+'_') for k in ['L', 'U', 'h1', 'o1', 'h2', 'o2']}\n",
    "\n",
    "dot = make_dot(L_, params=params)\n",
    "# Save Graph to `computation_graph_2.pdf`\n",
    "dot.render(data_dir + 'computation_graph_2')\n",
    "dot"
   ],
   "outputs": [
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 12.2.1 (20241206.2353)\n -->\n<!-- Pages: 1 -->\n<svg width=\"189pt\" height=\"684pt\"\n viewBox=\"0.00 0.00 189.00 684.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 680)\">\n<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-680 185,-680 185,4 -4,4\"/>\n<!-- 4999831216 -->\n<g id=\"node1\" class=\"node\">\n<title>4999831216</title>\n<polygon fill=\"#caff70\" stroke=\"black\" points=\"89,-36.5 35,-36.5 35,0 89,0 89,-36.5\"/>\n<text text-anchor=\"middle\" x=\"62\" y=\"-21.1\" font-family=\"Times,serif\" font-size=\"12.00\">Add</text>\n<text text-anchor=\"middle\" x=\"62\" y=\"-6.85\" font-family=\"Times,serif\" font-size=\"12.00\">L</text>\n</g>\n<!-- 4550651472 -->\n<g id=\"node2\" class=\"node\">\n<title>4550651472</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"54,-218.38 0,-218.38 0,-196.12 54,-196.12 54,-218.38\"/>\n<text text-anchor=\"middle\" x=\"27\" y=\"-202.97\" font-family=\"Times,serif\" font-size=\"12.00\">Pow</text>\n</g>\n<!-- 4550651472&#45;&gt;4999831216 -->\n<g id=\"edge1\" class=\"edge\">\n<title>4550651472&#45;&gt;4999831216</title>\n<path fill=\"none\" stroke=\"black\" d=\"M28.98,-195.66C34.24,-167.54 48.71,-90.27 56.63,-47.92\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"60.05,-48.69 58.45,-38.22 53.17,-47.4 60.05,-48.69\"/>\n</g>\n<!-- 5376060672 -->\n<g id=\"node3\" class=\"node\">\n<title>5376060672</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"54,-356.25 0,-356.25 0,-334 54,-334 54,-356.25\"/>\n<text text-anchor=\"middle\" x=\"27\" y=\"-340.85\" font-family=\"Times,serif\" font-size=\"12.00\">Sub</text>\n</g>\n<!-- 5376060672&#45;&gt;4550651472 -->\n<g id=\"edge2\" class=\"edge\">\n<title>5376060672&#45;&gt;4550651472</title>\n<path fill=\"none\" stroke=\"black\" d=\"M27,-333.91C27,-311.88 27,-259.48 27,-229.77\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"30.5,-230.09 27,-220.09 23.5,-230.09 30.5,-230.09\"/>\n</g>\n<!-- 5000498576 -->\n<g id=\"node4\" class=\"node\">\n<title>5000498576</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"54,-428.75 0,-428.75 0,-392.25 54,-392.25 54,-428.75\"/>\n<text text-anchor=\"middle\" x=\"27\" y=\"-413.35\" font-family=\"Times,serif\" font-size=\"12.00\">Mul</text>\n<text text-anchor=\"middle\" x=\"27\" y=\"-399.1\" font-family=\"Times,serif\" font-size=\"12.00\">o1</text>\n</g>\n<!-- 5000498576&#45;&gt;5376060672 -->\n<g id=\"edge3\" class=\"edge\">\n<title>5000498576&#45;&gt;5376060672</title>\n<path fill=\"none\" stroke=\"black\" d=\"M27,-391.85C27,-384.53 27,-375.97 27,-368.24\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"30.5,-368.26 27,-358.26 23.5,-368.26 30.5,-368.26\"/>\n</g>\n<!-- 5000498816 -->\n<g id=\"node5\" class=\"node\">\n<title>5000498816</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"109,-501.25 55,-501.25 55,-464.75 109,-464.75 109,-501.25\"/>\n<text text-anchor=\"middle\" x=\"82\" y=\"-485.85\" font-family=\"Times,serif\" font-size=\"12.00\">Clamp1</text>\n<text text-anchor=\"middle\" x=\"82\" y=\"-471.6\" font-family=\"Times,serif\" font-size=\"12.00\">h1</text>\n</g>\n<!-- 5000498816&#45;&gt;5000498576 -->\n<g id=\"edge4\" class=\"edge\">\n<title>5000498816&#45;&gt;5000498576</title>\n<path fill=\"none\" stroke=\"black\" d=\"M68.4,-464.57C62.17,-456.58 54.65,-446.94 47.73,-438.07\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"50.66,-436.14 41.75,-430.41 45.14,-440.45 50.66,-436.14\"/>\n</g>\n<!-- 5376060432 -->\n<g id=\"node15\" class=\"node\">\n<title>5376060432</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"126,-421.62 72,-421.62 72,-399.38 126,-399.38 126,-421.62\"/>\n<text text-anchor=\"middle\" x=\"99\" y=\"-406.23\" font-family=\"Times,serif\" font-size=\"12.00\">Mul</text>\n</g>\n<!-- 5000498816&#45;&gt;5376060432 -->\n<g id=\"edge16\" class=\"edge\">\n<title>5000498816&#45;&gt;5376060432</title>\n<path fill=\"none\" stroke=\"black\" d=\"M86.2,-464.57C88.5,-455.06 91.35,-443.21 93.79,-433.12\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"97.18,-433.97 96.12,-423.43 90.38,-432.33 97.18,-433.97\"/>\n</g>\n<!-- 5376058032 -->\n<g id=\"node6\" class=\"node\">\n<title>5376058032</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"109,-559.5 55,-559.5 55,-537.25 109,-537.25 109,-559.5\"/>\n<text text-anchor=\"middle\" x=\"82\" y=\"-544.1\" font-family=\"Times,serif\" font-size=\"12.00\">Add</text>\n</g>\n<!-- 5376058032&#45;&gt;5000498816 -->\n<g id=\"edge5\" class=\"edge\">\n<title>5376058032&#45;&gt;5000498816</title>\n<path fill=\"none\" stroke=\"black\" d=\"M82,-536.91C82,-530.34 82,-521.51 82,-512.94\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"85.5,-513.19 82,-503.19 78.5,-513.19 85.5,-513.19\"/>\n</g>\n<!-- 5376059136 -->\n<g id=\"node7\" class=\"node\">\n<title>5376059136</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"117,-617.75 63,-617.75 63,-595.5 117,-595.5 117,-617.75\"/>\n<text text-anchor=\"middle\" x=\"90\" y=\"-602.35\" font-family=\"Times,serif\" font-size=\"12.00\">Mul</text>\n</g>\n<!-- 5376059136&#45;&gt;5376058032 -->\n<g id=\"edge6\" class=\"edge\">\n<title>5376059136&#45;&gt;5376058032</title>\n<path fill=\"none\" stroke=\"black\" d=\"M88.5,-595.04C87.53,-588.29 86.25,-579.28 85.08,-571.05\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"88.58,-570.81 83.71,-561.41 81.65,-571.8 88.58,-570.81\"/>\n</g>\n<!-- 5376061248 -->\n<g id=\"node8\" class=\"node\">\n<title>5376061248</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"144,-676 90,-676 90,-653.75 144,-653.75 144,-676\"/>\n<text text-anchor=\"middle\" x=\"117\" y=\"-660.6\" font-family=\"Times,serif\" font-size=\"12.00\">U</text>\n</g>\n<!-- 5376061248&#45;&gt;5376059136 -->\n<g id=\"edge7\" class=\"edge\">\n<title>5376061248&#45;&gt;5376059136</title>\n<path fill=\"none\" stroke=\"black\" d=\"M111.92,-653.29C108.57,-646.3 104.05,-636.9 99.99,-628.45\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"103.19,-627.02 95.71,-619.52 96.88,-630.05 103.19,-627.02\"/>\n</g>\n<!-- 5376059088 -->\n<g id=\"node14\" class=\"node\">\n<title>5376059088</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"181,-559.5 127,-559.5 127,-537.25 181,-537.25 181,-559.5\"/>\n<text text-anchor=\"middle\" x=\"154\" y=\"-544.1\" font-family=\"Times,serif\" font-size=\"12.00\">Mul</text>\n</g>\n<!-- 5376061248&#45;&gt;5376059088 -->\n<g id=\"edge14\" class=\"edge\">\n<title>5376061248&#45;&gt;5376059088</title>\n<path fill=\"none\" stroke=\"black\" d=\"M120.41,-653.31C126.47,-634.56 139.21,-595.16 147.14,-570.61\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"150.38,-571.95 150.13,-561.36 143.72,-569.8 150.38,-571.95\"/>\n</g>\n<!-- 5376060816 -->\n<g id=\"node9\" class=\"node\">\n<title>5376060816</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"121,-94.75 67,-94.75 67,-72.5 121,-72.5 121,-94.75\"/>\n<text text-anchor=\"middle\" x=\"94\" y=\"-79.35\" font-family=\"Times,serif\" font-size=\"12.00\">Pow</text>\n</g>\n<!-- 5376060816&#45;&gt;4999831216 -->\n<g id=\"edge8\" class=\"edge\">\n<title>5376060816&#45;&gt;4999831216</title>\n<path fill=\"none\" stroke=\"black\" d=\"M88.72,-72.16C85.25,-65.29 80.53,-55.95 76.03,-47.03\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"79.24,-45.62 71.61,-38.28 72.99,-48.78 79.24,-45.62\"/>\n</g>\n<!-- 5376059568 -->\n<g id=\"node10\" class=\"node\">\n<title>5376059568</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"123,-153 69,-153 69,-130.75 123,-130.75 123,-153\"/>\n<text text-anchor=\"middle\" x=\"96\" y=\"-137.6\" font-family=\"Times,serif\" font-size=\"12.00\">Sub</text>\n</g>\n<!-- 5376059568&#45;&gt;5376060816 -->\n<g id=\"edge9\" class=\"edge\">\n<title>5376059568&#45;&gt;5376060816</title>\n<path fill=\"none\" stroke=\"black\" d=\"M95.62,-130.29C95.39,-123.62 95.07,-114.74 94.78,-106.59\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"98.28,-106.54 94.43,-96.67 91.29,-106.79 98.28,-106.54\"/>\n</g>\n<!-- 5000618192 -->\n<g id=\"node11\" class=\"node\">\n<title>5000618192</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"126,-225.5 72,-225.5 72,-189 126,-189 126,-225.5\"/>\n<text text-anchor=\"middle\" x=\"99\" y=\"-210.1\" font-family=\"Times,serif\" font-size=\"12.00\">Mul</text>\n<text text-anchor=\"middle\" x=\"99\" y=\"-195.85\" font-family=\"Times,serif\" font-size=\"12.00\">o2</text>\n</g>\n<!-- 5000618192&#45;&gt;5376059568 -->\n<g id=\"edge10\" class=\"edge\">\n<title>5000618192&#45;&gt;5376059568</title>\n<path fill=\"none\" stroke=\"black\" d=\"M98.16,-188.6C97.82,-181.28 97.41,-172.72 97.05,-164.99\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"100.54,-164.83 96.57,-155.01 93.55,-165.16 100.54,-164.83\"/>\n</g>\n<!-- 5000618144 -->\n<g id=\"node12\" class=\"node\">\n<title>5000618144</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"126,-298 72,-298 72,-261.5 126,-261.5 126,-298\"/>\n<text text-anchor=\"middle\" x=\"99\" y=\"-282.6\" font-family=\"Times,serif\" font-size=\"12.00\">Clamp1</text>\n<text text-anchor=\"middle\" x=\"99\" y=\"-268.35\" font-family=\"Times,serif\" font-size=\"12.00\">h2</text>\n</g>\n<!-- 5000618144&#45;&gt;5000618192 -->\n<g id=\"edge11\" class=\"edge\">\n<title>5000618144&#45;&gt;5000618192</title>\n<path fill=\"none\" stroke=\"black\" d=\"M99,-261.32C99,-254.09 99,-245.5 99,-237.36\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"102.5,-237.48 99,-227.48 95.5,-237.48 102.5,-237.48\"/>\n</g>\n<!-- 5376059808 -->\n<g id=\"node13\" class=\"node\">\n<title>5376059808</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"126,-356.25 72,-356.25 72,-334 126,-334 126,-356.25\"/>\n<text text-anchor=\"middle\" x=\"99\" y=\"-340.85\" font-family=\"Times,serif\" font-size=\"12.00\">Add</text>\n</g>\n<!-- 5376059808&#45;&gt;5000618144 -->\n<g id=\"edge12\" class=\"edge\">\n<title>5376059808&#45;&gt;5000618144</title>\n<path fill=\"none\" stroke=\"black\" d=\"M99,-333.66C99,-327.09 99,-318.26 99,-309.69\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"102.5,-309.94 99,-299.94 95.5,-309.94 102.5,-309.94\"/>\n</g>\n<!-- 5376059088&#45;&gt;5376059808 -->\n<g id=\"edge13\" class=\"edge\">\n<title>5376059088&#45;&gt;5376059808</title>\n<path fill=\"none\" stroke=\"black\" d=\"M154.59,-537.1C155.66,-511.53 156.16,-443.4 135,-392.25 130.87,-382.27 123.95,-372.61 117.28,-364.74\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"120.07,-362.6 110.76,-357.53 114.87,-367.3 120.07,-362.6\"/>\n</g>\n<!-- 5376060432&#45;&gt;5376059808 -->\n<g id=\"edge15\" class=\"edge\">\n<title>5376060432&#45;&gt;5376059808</title>\n<path fill=\"none\" stroke=\"black\" d=\"M99,-399.03C99,-390.54 99,-378.29 99,-367.72\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"102.5,-367.91 99,-357.91 95.5,-367.91 102.5,-367.91\"/>\n</g>\n</g>\n</svg>\n",
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x10f3d6880>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "id": "60e85c7f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "60e85c7f"
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question:** This time, find the formula for $\\frac{\\partial L(\\vect{U}, \\vect{V}, \\vect{W}, x_1, x_2, x_3, h_0)}{\\partial \\vect{U}}$, the derivative of the loss $L$ with respect to the parameter $\\vect{U}$ in terms of $\\frac{\\partial L(o_1, o_2, x_2, x_3)}{\\partial o_t}$, $\\frac{\\partial o_t( \\vect{W}, h_t)}{\\partial h_t}$, $\\frac{\\partial h_2(\\vect{U}, \\vect{V}, h_1, x_2)}{\\partial h_1}$, and $\\frac{\\partial h_t(\\vect{U}, \\vect{V}, h_{t-1}, x_t)}{\\partial \\vect{U}}$ for $t \\in \\{1,2\\}$. You might find the above computation graph useful.\n",
    "\n",
    "> How many possible paths are there in the computation graph from $\\vect{U}$ to $L$? Each path corresponds to a term in the final answer.\n",
    "\n",
    "> Hint: when we take $\\frac{\\partial h_2(\\vect{U}, \\vect{V}, h_1, x_2)}{\\partial \\vect{U}}$, we are holding other arguments (other than $\\vect{U}$) as constants, such as $h_1$. Therefore, $\\frac{\\partial h_2}{\\partial \\vect{U}}$ does not reflect the path through $h_1$ where $\\vect{U}$ can also exert influence on $h_2$: $\\vect{U} \\to h_1 \\to h_2$.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: open_response_backprop2\n",
    "manual: true\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c15914",
   "metadata": {},
   "source": [
    "$ o_1 = Wh_1 $\n",
    "\n",
    "$ o_2 = Wh_2 $\n",
    "\n",
    "$ L = (x_3 - o_2)^2 + (x_2 - o_1)^2 = (x_3 - Wh_2)^2 + (x_2 - Wh_1)^2 $\n",
    "\n",
    "$\\frac{\\partial L(\\vect{U}, \\vect{V}, \\vect{W}, x_1, x_2, x_3, h_0)}{\\partial \\vect{U}}$\n",
    "$ = (\\frac{\\partial L(o_1, o_2, x_2, x_3)}{\\partial o_1})(\\frac{\\partial o_1( \\vect{W}, h_1)}{\\partial h_1})(\\frac{\\partial h_1(\\vect{U}, \\vect{V}, h_{0}, x_1)}{\\partial \\vect{U}})$\n",
    "$ + \\frac{\\partial L(o_1, o_2, x_2, x_3)}{\\partial o_2} \\cdot \\frac{\\partial o_2( \\vect{W}, h_2)}{\\partial h_2} \\cdot (\\frac{\\partial h_2(\\vect{U}, \\vect{V}, h_1, x_2)}{\\partial h_1}\\frac{\\partial h_1(\\vect{U}, \\vect{V}, h_{0}, x_1)}{\\partial \\vect{U}} + \\frac{\\partial h_2(\\vect{U}, \\vect{V}, h_{1}, x_2)}{\\partial \\vect{U}})$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aecdece",
   "metadata": {
    "id": "8aecdece"
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "## RNN backprop on short sequences\n",
    "\n",
    "For the penultimate backprop challenge, consider an RNN run on an input sequence of length 3. This RNN's output sequence $o$ will consist of $o_1$, $o_2$, and $o_3$.\n",
    "\n",
    "Let's look at the computation graph. How many possible paths are there from $\\vect{U}$ to $L$? How many $h$ elements are there in each path?"
   ]
  },
  {
   "cell_type": "code",
   "id": "f2139a63",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "execution": {
     "iopub.execute_input": "2024-12-09T07:28:10.279964Z",
     "iopub.status.busy": "2024-12-09T07:28:10.279362Z",
     "iopub.status.idle": "2024-12-09T07:28:10.355511Z",
     "shell.execute_reply": "2024-12-09T07:28:10.354536Z"
    },
    "id": "f2139a63",
    "outputId": "765519b5-ca46-4218-ccc2-79f0b82479b9",
    "ExecuteTime": {
     "end_time": "2024-12-11T18:13:46.557451Z",
     "start_time": "2024-12-11T18:13:46.421908Z"
    }
   },
   "source": [
    "# RNN parameters\n",
    "U_ = torch.Tensor([0.1])\n",
    "V_ = torch.Tensor([0.2])\n",
    "W_ = torch.Tensor([0.3])\n",
    "\n",
    "# inputs\n",
    "x1_ = torch.Tensor([0.5])\n",
    "x2_ = torch.Tensor([0.6])\n",
    "x3_ = torch.Tensor([0.7])\n",
    "x4_ = torch.Tensor([0.8])\n",
    "\n",
    "# initial value for the hidden state, a zero vector\n",
    "h0_ = torch.Tensor([0])\n",
    "\n",
    "# Set which nodes to visualize later\n",
    "visualized_nodes = [U_, ]\n",
    "for p in visualized_nodes:\n",
    "    p.requires_grad = True\n",
    "\n",
    "# Calculate h1, o1\n",
    "h1_ = relu(U_ * x1_ + V_ * h0_)\n",
    "h2_ = relu(U_ * x2_ + V_ * h1_)\n",
    "h3_ = relu(U_ * x3_ + V_ * h2_)\n",
    "o3_ = W_ * h3_\n",
    "o2_ = W_ * h2_\n",
    "o1_ = W_ * h1_\n",
    "\n",
    "L_ = (o1_ - x2_)**2 + (o2_ - x3_)**2 + (o3_ - x4_)**2\n",
    "\n",
    "params = {k: eval(k+'_') for k in ['L', 'U', 'h1', 'o1', 'h2', 'o2', 'h3', 'o3']}\n",
    "\n",
    "dot = make_dot(L_, params=params)\n",
    "# Save Graph to `computation_graph_3.pdf`\n",
    "dot.render(data_dir + 'computation_graph_3')\n",
    "dot"
   ],
   "outputs": [
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 12.2.1 (20241206.2353)\n -->\n<!-- Pages: 1 -->\n<svg width=\"238pt\" height=\"864pt\"\n viewBox=\"0.00 0.00 237.61 864.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(0.973795 0.973795) rotate(0) translate(4 883.25)\">\n<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-883.25 240,-883.25 240,4 -4,4\"/>\n<!-- 4999922784 -->\n<g id=\"node1\" class=\"node\">\n<title>4999922784</title>\n<polygon fill=\"#caff70\" stroke=\"black\" points=\"144,-36.5 90,-36.5 90,0 144,0 144,-36.5\"/>\n<text text-anchor=\"middle\" x=\"117\" y=\"-21.1\" font-family=\"Times,serif\" font-size=\"12.00\">Add</text>\n<text text-anchor=\"middle\" x=\"117\" y=\"-6.85\" font-family=\"Times,serif\" font-size=\"12.00\">L</text>\n</g>\n<!-- 5000526432 -->\n<g id=\"node2\" class=\"node\">\n<title>5000526432</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"109,-218.38 55,-218.38 55,-196.12 109,-196.12 109,-218.38\"/>\n<text text-anchor=\"middle\" x=\"82\" y=\"-202.97\" font-family=\"Times,serif\" font-size=\"12.00\">Add</text>\n</g>\n<!-- 5000526432&#45;&gt;4999922784 -->\n<g id=\"edge1\" class=\"edge\">\n<title>5000526432&#45;&gt;4999922784</title>\n<path fill=\"none\" stroke=\"black\" d=\"M83.98,-195.66C89.24,-167.54 103.71,-90.27 111.63,-47.92\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"115.05,-48.69 113.45,-38.22 108.17,-47.4 115.05,-48.69\"/>\n</g>\n<!-- 5000525136 -->\n<g id=\"node3\" class=\"node\">\n<title>5000525136</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"54,-494.12 0,-494.12 0,-471.88 54,-471.88 54,-494.12\"/>\n<text text-anchor=\"middle\" x=\"27\" y=\"-478.73\" font-family=\"Times,serif\" font-size=\"12.00\">Pow</text>\n</g>\n<!-- 5000525136&#45;&gt;5000526432 -->\n<g id=\"edge2\" class=\"edge\">\n<title>5000525136&#45;&gt;5000526432</title>\n<path fill=\"none\" stroke=\"black\" d=\"M26.08,-471.5C23.63,-439.11 18.82,-338.29 46,-261.5 50.31,-249.32 58.09,-237.27 65.31,-227.71\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"68.01,-229.94 71.53,-219.95 62.54,-225.57 68.01,-229.94\"/>\n</g>\n<!-- 5000527296 -->\n<g id=\"node4\" class=\"node\">\n<title>5000527296</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"54,-559.5 0,-559.5 0,-537.25 54,-537.25 54,-559.5\"/>\n<text text-anchor=\"middle\" x=\"27\" y=\"-544.1\" font-family=\"Times,serif\" font-size=\"12.00\">Sub</text>\n</g>\n<!-- 5000527296&#45;&gt;5000525136 -->\n<g id=\"edge3\" class=\"edge\">\n<title>5000527296&#45;&gt;5000525136</title>\n<path fill=\"none\" stroke=\"black\" d=\"M27,-536.91C27,-528.42 27,-516.17 27,-505.59\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"30.5,-505.78 27,-495.78 23.5,-505.78 30.5,-505.78\"/>\n</g>\n<!-- 4999922832 -->\n<g id=\"node5\" class=\"node\">\n<title>4999922832</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"54,-632 0,-632 0,-595.5 54,-595.5 54,-632\"/>\n<text text-anchor=\"middle\" x=\"27\" y=\"-616.6\" font-family=\"Times,serif\" font-size=\"12.00\">Mul</text>\n<text text-anchor=\"middle\" x=\"27\" y=\"-602.35\" font-family=\"Times,serif\" font-size=\"12.00\">o1</text>\n</g>\n<!-- 4999922832&#45;&gt;5000527296 -->\n<g id=\"edge4\" class=\"edge\">\n<title>4999922832&#45;&gt;5000527296</title>\n<path fill=\"none\" stroke=\"black\" d=\"M27,-595.1C27,-587.78 27,-579.22 27,-571.49\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"30.5,-571.51 27,-561.51 23.5,-571.51 30.5,-571.51\"/>\n</g>\n<!-- 4999923936 -->\n<g id=\"node6\" class=\"node\">\n<title>4999923936</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"109,-704.5 55,-704.5 55,-668 109,-668 109,-704.5\"/>\n<text text-anchor=\"middle\" x=\"82\" y=\"-689.1\" font-family=\"Times,serif\" font-size=\"12.00\">Clamp1</text>\n<text text-anchor=\"middle\" x=\"82\" y=\"-674.85\" font-family=\"Times,serif\" font-size=\"12.00\">h1</text>\n</g>\n<!-- 4999923936&#45;&gt;4999922832 -->\n<g id=\"edge5\" class=\"edge\">\n<title>4999923936&#45;&gt;4999922832</title>\n<path fill=\"none\" stroke=\"black\" d=\"M68.4,-667.82C62.17,-659.83 54.65,-650.19 47.73,-641.32\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"50.66,-639.39 41.75,-633.66 45.14,-643.7 50.66,-639.39\"/>\n</g>\n<!-- 5376060384 -->\n<g id=\"node16\" class=\"node\">\n<title>5376060384</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"126,-624.88 72,-624.88 72,-602.62 126,-602.62 126,-624.88\"/>\n<text text-anchor=\"middle\" x=\"99\" y=\"-609.48\" font-family=\"Times,serif\" font-size=\"12.00\">Mul</text>\n</g>\n<!-- 4999923936&#45;&gt;5376060384 -->\n<g id=\"edge17\" class=\"edge\">\n<title>4999923936&#45;&gt;5376060384</title>\n<path fill=\"none\" stroke=\"black\" d=\"M86.2,-667.82C88.5,-658.31 91.35,-646.46 93.79,-636.37\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"97.18,-637.22 96.12,-626.68 90.38,-635.58 97.18,-637.22\"/>\n</g>\n<!-- 5376058272 -->\n<g id=\"node7\" class=\"node\">\n<title>5376058272</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"114,-762.75 60,-762.75 60,-740.5 114,-740.5 114,-762.75\"/>\n<text text-anchor=\"middle\" x=\"87\" y=\"-747.35\" font-family=\"Times,serif\" font-size=\"12.00\">Add</text>\n</g>\n<!-- 5376058272&#45;&gt;4999923936 -->\n<g id=\"edge6\" class=\"edge\">\n<title>5376058272&#45;&gt;4999923936</title>\n<path fill=\"none\" stroke=\"black\" d=\"M86.17,-740.16C85.66,-733.59 84.96,-724.76 84.28,-716.19\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"87.79,-716.13 83.51,-706.43 80.81,-716.68 87.79,-716.13\"/>\n</g>\n<!-- 5376058416 -->\n<g id=\"node8\" class=\"node\">\n<title>5376058416</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"122,-821 68,-821 68,-798.75 122,-798.75 122,-821\"/>\n<text text-anchor=\"middle\" x=\"95\" y=\"-805.6\" font-family=\"Times,serif\" font-size=\"12.00\">Mul</text>\n</g>\n<!-- 5376058416&#45;&gt;5376058272 -->\n<g id=\"edge7\" class=\"edge\">\n<title>5376058416&#45;&gt;5376058272</title>\n<path fill=\"none\" stroke=\"black\" d=\"M93.5,-798.29C92.53,-791.54 91.25,-782.53 90.08,-774.3\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"93.58,-774.06 88.71,-764.66 86.65,-775.05 93.58,-774.06\"/>\n</g>\n<!-- 5376059280 -->\n<g id=\"node9\" class=\"node\">\n<title>5376059280</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"181,-879.25 127,-879.25 127,-857 181,-857 181,-879.25\"/>\n<text text-anchor=\"middle\" x=\"154\" y=\"-863.85\" font-family=\"Times,serif\" font-size=\"12.00\">U</text>\n</g>\n<!-- 5376059280&#45;&gt;5376058416 -->\n<g id=\"edge8\" class=\"edge\">\n<title>5376059280&#45;&gt;5376058416</title>\n<path fill=\"none\" stroke=\"black\" d=\"M142.9,-856.54C134.83,-848.85 123.69,-838.22 114.18,-829.16\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"116.8,-826.82 107.14,-822.45 111.97,-831.89 116.8,-826.82\"/>\n</g>\n<!-- 5376058032 -->\n<g id=\"node15\" class=\"node\">\n<title>5376058032</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"181,-697.38 127,-697.38 127,-675.12 181,-675.12 181,-697.38\"/>\n<text text-anchor=\"middle\" x=\"154\" y=\"-681.98\" font-family=\"Times,serif\" font-size=\"12.00\">Mul</text>\n</g>\n<!-- 5376059280&#45;&gt;5376058032 -->\n<g id=\"edge15\" class=\"edge\">\n<title>5376059280&#45;&gt;5376058032</title>\n<path fill=\"none\" stroke=\"black\" d=\"M154,-856.68C154,-828.05 154,-747.92 154,-709\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"157.5,-709.24 154,-699.24 150.5,-709.24 157.5,-709.24\"/>\n</g>\n<!-- 5376061248 -->\n<g id=\"node22\" class=\"node\">\n<title>5376061248</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"236,-762.75 182,-762.75 182,-740.5 236,-740.5 236,-762.75\"/>\n<text text-anchor=\"middle\" x=\"209\" y=\"-747.35\" font-family=\"Times,serif\" font-size=\"12.00\">Mul</text>\n</g>\n<!-- 5376059280&#45;&gt;5376061248 -->\n<g id=\"edge24\" class=\"edge\">\n<title>5376059280&#45;&gt;5376061248</title>\n<path fill=\"none\" stroke=\"black\" d=\"M159.08,-856.56C168.12,-837.73 187.18,-798.05 198.96,-773.53\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"202.11,-775.06 203.28,-764.53 195.8,-772.03 202.11,-775.06\"/>\n</g>\n<!-- 5000524704 -->\n<g id=\"node10\" class=\"node\">\n<title>5000524704</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"109,-290.88 55,-290.88 55,-268.62 109,-268.62 109,-290.88\"/>\n<text text-anchor=\"middle\" x=\"82\" y=\"-275.48\" font-family=\"Times,serif\" font-size=\"12.00\">Pow</text>\n</g>\n<!-- 5000524704&#45;&gt;5000526432 -->\n<g id=\"edge9\" class=\"edge\">\n<title>5000524704&#45;&gt;5000526432</title>\n<path fill=\"none\" stroke=\"black\" d=\"M82,-268.35C82,-258.25 82,-242.61 82,-229.81\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"85.5,-230.21 82,-220.21 78.5,-230.21 85.5,-230.21\"/>\n</g>\n<!-- 5000526864 -->\n<g id=\"node11\" class=\"node\">\n<title>5000526864</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"109,-356.25 55,-356.25 55,-334 109,-334 109,-356.25\"/>\n<text text-anchor=\"middle\" x=\"82\" y=\"-340.85\" font-family=\"Times,serif\" font-size=\"12.00\">Sub</text>\n</g>\n<!-- 5000526864&#45;&gt;5000524704 -->\n<g id=\"edge10\" class=\"edge\">\n<title>5000526864&#45;&gt;5000524704</title>\n<path fill=\"none\" stroke=\"black\" d=\"M82,-333.66C82,-325.17 82,-312.92 82,-302.34\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"85.5,-302.53 82,-292.53 78.5,-302.53 85.5,-302.53\"/>\n</g>\n<!-- 5000526720 -->\n<g id=\"node12\" class=\"node\">\n<title>5000526720</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"109,-428.75 55,-428.75 55,-392.25 109,-392.25 109,-428.75\"/>\n<text text-anchor=\"middle\" x=\"82\" y=\"-413.35\" font-family=\"Times,serif\" font-size=\"12.00\">Mul</text>\n<text text-anchor=\"middle\" x=\"82\" y=\"-399.1\" font-family=\"Times,serif\" font-size=\"12.00\">o2</text>\n</g>\n<!-- 5000526720&#45;&gt;5000526864 -->\n<g id=\"edge11\" class=\"edge\">\n<title>5000526720&#45;&gt;5000526864</title>\n<path fill=\"none\" stroke=\"black\" d=\"M82,-391.85C82,-384.53 82,-375.97 82,-368.24\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"85.5,-368.26 82,-358.26 78.5,-368.26 85.5,-368.26\"/>\n</g>\n<!-- 4999923648 -->\n<g id=\"node13\" class=\"node\">\n<title>4999923648</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"154,-501.25 100,-501.25 100,-464.75 154,-464.75 154,-501.25\"/>\n<text text-anchor=\"middle\" x=\"127\" y=\"-485.85\" font-family=\"Times,serif\" font-size=\"12.00\">Clamp1</text>\n<text text-anchor=\"middle\" x=\"127\" y=\"-471.6\" font-family=\"Times,serif\" font-size=\"12.00\">h2</text>\n</g>\n<!-- 4999923648&#45;&gt;5000526720 -->\n<g id=\"edge12\" class=\"edge\">\n<title>4999923648&#45;&gt;5000526720</title>\n<path fill=\"none\" stroke=\"black\" d=\"M115.88,-464.57C110.94,-456.84 105.01,-447.54 99.5,-438.91\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"102.45,-437.04 94.12,-430.49 96.55,-440.8 102.45,-437.04\"/>\n</g>\n<!-- 5376057696 -->\n<g id=\"node23\" class=\"node\">\n<title>5376057696</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"181,-421.62 127,-421.62 127,-399.38 181,-399.38 181,-421.62\"/>\n<text text-anchor=\"middle\" x=\"154\" y=\"-406.23\" font-family=\"Times,serif\" font-size=\"12.00\">Mul</text>\n</g>\n<!-- 4999923648&#45;&gt;5376057696 -->\n<g id=\"edge26\" class=\"edge\">\n<title>4999923648&#45;&gt;5376057696</title>\n<path fill=\"none\" stroke=\"black\" d=\"M133.67,-464.57C137.4,-454.86 142.06,-442.69 145.98,-432.45\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"149.15,-433.96 149.45,-423.37 142.61,-431.45 149.15,-433.96\"/>\n</g>\n<!-- 5376059184 -->\n<g id=\"node14\" class=\"node\">\n<title>5376059184</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"154,-559.5 100,-559.5 100,-537.25 154,-537.25 154,-559.5\"/>\n<text text-anchor=\"middle\" x=\"127\" y=\"-544.1\" font-family=\"Times,serif\" font-size=\"12.00\">Add</text>\n</g>\n<!-- 5376059184&#45;&gt;4999923648 -->\n<g id=\"edge13\" class=\"edge\">\n<title>5376059184&#45;&gt;4999923648</title>\n<path fill=\"none\" stroke=\"black\" d=\"M127,-536.91C127,-530.34 127,-521.51 127,-512.94\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"130.5,-513.19 127,-503.19 123.5,-513.19 130.5,-513.19\"/>\n</g>\n<!-- 5376058032&#45;&gt;5376059184 -->\n<g id=\"edge14\" class=\"edge\">\n<title>5376058032&#45;&gt;5376059184</title>\n<path fill=\"none\" stroke=\"black\" d=\"M151.97,-675.04C147.59,-653 137.18,-600.6 131.28,-570.89\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"134.73,-570.32 129.35,-561.19 127.86,-571.68 134.73,-570.32\"/>\n</g>\n<!-- 5376060384&#45;&gt;5376059184 -->\n<g id=\"edge16\" class=\"edge\">\n<title>5376060384&#45;&gt;5376059184</title>\n<path fill=\"none\" stroke=\"black\" d=\"M103.62,-602.28C107.5,-593.52 113.14,-580.74 117.92,-569.94\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"121.01,-571.59 121.85,-561.03 114.61,-568.76 121.01,-571.59\"/>\n</g>\n<!-- 5000524608 -->\n<g id=\"node17\" class=\"node\">\n<title>5000524608</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"176,-94.75 122,-94.75 122,-72.5 176,-72.5 176,-94.75\"/>\n<text text-anchor=\"middle\" x=\"149\" y=\"-79.35\" font-family=\"Times,serif\" font-size=\"12.00\">Pow</text>\n</g>\n<!-- 5000524608&#45;&gt;4999922784 -->\n<g id=\"edge18\" class=\"edge\">\n<title>5000524608&#45;&gt;4999922784</title>\n<path fill=\"none\" stroke=\"black\" d=\"M143.72,-72.16C140.25,-65.29 135.53,-55.95 131.03,-47.03\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"134.24,-45.62 126.61,-38.28 127.99,-48.78 134.24,-45.62\"/>\n</g>\n<!-- 5000526480 -->\n<g id=\"node18\" class=\"node\">\n<title>5000526480</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"178,-153 124,-153 124,-130.75 178,-130.75 178,-153\"/>\n<text text-anchor=\"middle\" x=\"151\" y=\"-137.6\" font-family=\"Times,serif\" font-size=\"12.00\">Sub</text>\n</g>\n<!-- 5000526480&#45;&gt;5000524608 -->\n<g id=\"edge19\" class=\"edge\">\n<title>5000526480&#45;&gt;5000524608</title>\n<path fill=\"none\" stroke=\"black\" d=\"M150.62,-130.29C150.39,-123.62 150.07,-114.74 149.78,-106.59\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"153.28,-106.54 149.43,-96.67 146.29,-106.79 153.28,-106.54\"/>\n</g>\n<!-- 5000526528 -->\n<g id=\"node19\" class=\"node\">\n<title>5000526528</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"181,-225.5 127,-225.5 127,-189 181,-189 181,-225.5\"/>\n<text text-anchor=\"middle\" x=\"154\" y=\"-210.1\" font-family=\"Times,serif\" font-size=\"12.00\">Mul</text>\n<text text-anchor=\"middle\" x=\"154\" y=\"-195.85\" font-family=\"Times,serif\" font-size=\"12.00\">o3</text>\n</g>\n<!-- 5000526528&#45;&gt;5000526480 -->\n<g id=\"edge20\" class=\"edge\">\n<title>5000526528&#45;&gt;5000526480</title>\n<path fill=\"none\" stroke=\"black\" d=\"M153.16,-188.6C152.82,-181.28 152.41,-172.72 152.05,-164.99\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"155.54,-164.83 151.57,-155.01 148.55,-165.16 155.54,-164.83\"/>\n</g>\n<!-- 5000527680 -->\n<g id=\"node20\" class=\"node\">\n<title>5000527680</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"181,-298 127,-298 127,-261.5 181,-261.5 181,-298\"/>\n<text text-anchor=\"middle\" x=\"154\" y=\"-282.6\" font-family=\"Times,serif\" font-size=\"12.00\">Clamp1</text>\n<text text-anchor=\"middle\" x=\"154\" y=\"-268.35\" font-family=\"Times,serif\" font-size=\"12.00\">h3</text>\n</g>\n<!-- 5000527680&#45;&gt;5000526528 -->\n<g id=\"edge21\" class=\"edge\">\n<title>5000527680&#45;&gt;5000526528</title>\n<path fill=\"none\" stroke=\"black\" d=\"M154,-261.32C154,-254.09 154,-245.5 154,-237.36\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"157.5,-237.48 154,-227.48 150.5,-237.48 157.5,-237.48\"/>\n</g>\n<!-- 5376058944 -->\n<g id=\"node21\" class=\"node\">\n<title>5376058944</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"181,-356.25 127,-356.25 127,-334 181,-334 181,-356.25\"/>\n<text text-anchor=\"middle\" x=\"154\" y=\"-340.85\" font-family=\"Times,serif\" font-size=\"12.00\">Add</text>\n</g>\n<!-- 5376058944&#45;&gt;5000527680 -->\n<g id=\"edge22\" class=\"edge\">\n<title>5376058944&#45;&gt;5000527680</title>\n<path fill=\"none\" stroke=\"black\" d=\"M154,-333.66C154,-327.09 154,-318.26 154,-309.69\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"157.5,-309.94 154,-299.94 150.5,-309.94 157.5,-309.94\"/>\n</g>\n<!-- 5376061248&#45;&gt;5376058944 -->\n<g id=\"edge23\" class=\"edge\">\n<title>5376061248&#45;&gt;5376058944</title>\n<path fill=\"none\" stroke=\"black\" d=\"M209,-740.05C209,-717.2 209,-661.46 209,-614.75 209,-614.75 209,-614.75 209,-482 209,-441.23 207.21,-429.21 190,-392.25 185.44,-382.45 178.45,-372.83 171.84,-364.94\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"174.68,-362.86 165.43,-357.68 169.43,-367.49 174.68,-362.86\"/>\n</g>\n<!-- 5376057696&#45;&gt;5376058944 -->\n<g id=\"edge25\" class=\"edge\">\n<title>5376057696&#45;&gt;5376058944</title>\n<path fill=\"none\" stroke=\"black\" d=\"M154,-399.03C154,-390.54 154,-378.29 154,-367.72\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"157.5,-367.91 154,-357.91 150.5,-367.91 157.5,-367.91\"/>\n</g>\n</g>\n</svg>\n",
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x12a0dfca0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "id": "643b591f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "643b591f"
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question:** This time, find the formula for $\\frac{\\partial L(\\vect{U}, \\vect{V}, \\vect{W}, x_1, x_2, x_3, x_4, h_0)}{\\partial \\vect{U}}$ in terms of $\\frac{\\partial L(o_1,o_2,o_3,x_2,x_3,x_{4})}{\\partial o_t}$, $\\frac{\\partial o_t(\\vect{W}, h_t)}{\\partial h_t}$, $\\frac{\\partial h_t(\\vect{U}, \\vect{V}, h_{t-1}, x_t)}{\\partial h_{t-1}}$, and $\\frac{\\partial h_t(\\vect{U}, \\vect{V}, h_{t-1}, x_t)}{\\partial \\vect{U}}$ for $t \\in \\{1, 2, 3\\}$.\n",
    "\n",
    "> You should start to see a pattern emerging from this solution.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: open_response_backprop3\n",
    "manual: true\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c044006",
   "metadata": {},
   "source": [
    "$ o_i = Wh_i $\n",
    "\n",
    "$ L = (x_4 - o_3)^2 + (x_3 - o_2)^2 + (x_2 - o_1)^2 = (x_4 - Wh_3)^2 + (x_3 - Wh_2)^2 + (x_2 - Wh_1)^2 $\n",
    "\n",
    "$\\frac{\\partial L(\\vect{U}, \\vect{V}, \\vect{W}, x_1, x_2, x_3, x_4, h_0)}{\\partial \\vect{U}}$\n",
    "$ = \\frac{\\partial L(o_1,o_2,o_3,x_2,x_3,x_{4})}{\\partial o_1} \\cdot \\frac{\\partial o_1(\\vect{W}, h_1)}{\\partial h_1} \\cdot \\frac{\\partial h_1(\\vect{U}, \\vect{V}, h_0, x_1)}{\\partial \\vect{U}} $\n",
    "$ + \\frac{\\partial L(o_1,o_2,o_3,x_2,x_3,x_{4})}{\\partial o_2} \\cdot \\frac{\\partial o_2(\\vect{W}, h_2)}{\\partial h_2} \\cdot ( \\frac{\\partial h_2(\\vect{U}, \\vect{V}, h_{1}, x_2)}{\\partial h_{1}} \\cdot \\frac{\\partial h_1(\\vect{U}, \\vect{V}, h_{0}, x_1)}{\\partial \\vect{U}} + \\frac{\\partial h_2(\\vect{U}, \\vect{V}, h_1, x_2)}{\\partial \\vect{U}})$\n",
    "$ + \\frac{\\partial L(o_1,o_2,o_3,x_2,x_3,x_{4})}{\\partial o_3} \\cdot \\frac{\\partial o_3(\\vect{W}, h_3)}{\\partial h_3} \\cdot (\\frac{\\partial h_3(\\vect{U}, \\vect{V}, h_{2}, x_3)}{\\partial h_{2}} ( \\frac{\\partial h_2(\\vect{U}, \\vect{V}, h_{1}, x_2)}{\\partial h_{1}} \\cdot \\frac{\\partial h_1(\\vect{U}, \\vect{V}, h_{0}, x_1)}{\\partial \\vect{U}} + \\frac{\\partial h_2(\\vect{U}, \\vect{V}, h_1, x_2)}{\\partial \\vect{U}}) + \\frac{\\partial h_3(\\vect{U}, \\vect{V}, h_2, x_3)}{\\partial \\vect{U}})$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5f4d8a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "6f5f4d8a"
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## Looking back\n",
    "\n",
    "In the last few problems your answers were in terms of partial derivatives that we gave you. In this exercise you will calculate part of a partial derivative.\n",
    "\n",
    "**Question:** Referring back to the first problem in this lab, recall that\n",
    "\n",
    "$$ \\vect{U} = \\begin{bmatrix} -0.3 & 0.6 \\\\ 0.2 & 0.1 \\end{bmatrix}, \\vect{V} = \\begin{bmatrix} 0.4 & 0.4 \\\\ 0.9 & -0.7 \\end{bmatrix}, x_1 = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix},   h_0 = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}$$\n",
    "               \n",
    "Find the partial derivative $\\frac{\\partial h_{1}}{\\partial U_{1,1}}$, where $U_{1,1}$ is the element in the first row and first column of the matrix $\\vect{U}$.\n",
    "\n",
    "> **Hint:** We didn't tell you what the function $\\sigma$ is. It turns out that you will not need it! If you set it up right, you will see that you will not have to do much math at all.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: open_response_looking_back\n",
    "manual: true\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc4b664",
   "metadata": {},
   "source": [
    "$ h_1 = \\sigma (\\vect{U}x_1 + \\vect{V}h_0) = \\sigma (\\vect{U}x_1)$\n",
    "$ = \\sigma( \\begin{bmatrix} U_{1,1} & U_{1,2} \\\\ U_{2,1} & U_{2,2} \\end{bmatrix} \\begin{bmatrix} x_{1,1} \\\\ x_{1,2} \\end{bmatrix}) $\n",
    "$ = \\sigma(\\begin{bmatrix} U_{1,1} \\cdot x_{1,1} + U_{1,2} \\cdot x_{1,2}  \\\\ U_{2,1} \\cdot x_{1,1} + U_{2,2} \\cdot x_{1,2} \\end{bmatrix})) $\n",
    "\n",
    "$\\frac{\\partial h_{1}}{\\partial U_{1,1}} = \\sigma'(\\begin{bmatrix} U_{1,1} \\cdot x_{1,1} + U_{1,2} \\cdot x_{1,2}  \\\\ U_{2,1} \\cdot x_{1,1} + U_{2,2} \\cdot x_{1,2} \\end{bmatrix}) \\cdot \\begin{bmatrix} x_{1,1} \\\\ 0 \\end{bmatrix}$\n",
    "$ = \\sigma'(\\begin{bmatrix} U_{1,1} \\cdot x_{1,1} + U_{1,2} \\cdot x_{1,2}  \\\\ U_{2,1} \\cdot x_{1,1} + U_{2,2} \\cdot x_{1,2} \\end{bmatrix}) \\cdot \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36398af",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "d36398af"
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "Now, let's verify your solution above using PyTorch, which can calculate gradients automatically. We show an example below of how to calculate gradients. Adapt it to find the gradients of $\\frac{\\partial h_{1,1}}{\\partial \\vect{U}}$ (where $h_{1,1}$ denotes the first element of vector $h_1$, and here we are taking the derivative with respect to the entire matrix $\\vect{U}$). Use ReLU as $\\sigma$.\n",
    "\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: automatic_diff\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "id": "f67f23b7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-12-09T07:28:10.359227Z",
     "iopub.status.busy": "2024-12-09T07:28:10.358829Z",
     "iopub.status.idle": "2024-12-09T07:28:10.366949Z",
     "shell.execute_reply": "2024-12-09T07:28:10.366187Z"
    },
    "id": "f67f23b7",
    "outputId": "ff3b1aa7-a3a1-4f6e-d068-9610e97a6148",
    "ExecuteTime": {
     "end_time": "2024-12-11T18:13:46.663413Z",
     "start_time": "2024-12-11T18:13:46.574062Z"
    }
   },
   "source": [
    "# TODO: modify the code below to find the gradients of\n",
    "# $\\frac{\\partial h_{1,1}}{\\partial \\vect{U}}$\n",
    "\n",
    "# RNN parameters\n",
    "U_ = torch.Tensor([ [-0.3,  0.6],\n",
    "               [ 0.2,  0.1] ])\n",
    "V_ = torch.Tensor([ [ 0.4,  0.4],\n",
    "               [ 0.9, -0.7] ])\n",
    "U_.requires_grad = True\n",
    "\n",
    "# inputs\n",
    "x1_ = torch.Tensor([0.0, 1.0])\n",
    "\n",
    "# initial value for the hidden state, a zero vector\n",
    "h0_ = torch.Tensor([0, 0])\n",
    "h1_ = relu(U_ @ x1 + V_ @ h0)\n",
    "h11 = h1_[0]\n",
    "\n",
    "# The magic gradient computation\n",
    "h11.backward()\n",
    "U_grad = U_.grad\n",
    "print (f'Gradient of W: {U_grad}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient of W: tensor([[0., 1.],\n",
      "        [0., 0.]])\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "id": "00d65780",
   "metadata": {
    "deletable": false,
    "editable": false,
    "ExecuteTime": {
     "end_time": "2024-12-11T18:13:46.688357Z",
     "start_time": "2024-12-11T18:13:46.681913Z"
    }
   },
   "source": [
    "grader.check(\"automatic_diff\")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "    All tests passed!\n",
       "    "
      ],
      "text/html": [
       "\n",
       "    \n",
       "    \n",
       "        <p>All tests passed!</p>\n",
       "    \n",
       "    "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "id": "9d9e44cd",
   "metadata": {
    "id": "9d9e44cd"
   },
   "source": "Does the computed gradient agree with your calculation of $\\frac{\\partial h_{1}}{\\partial U_{1,1}}$? (Note that here you only calculated $\\frac{\\partial h_{1,1}}{\\partial \\vect{U}}$ through PyTorch, so let's just focus on $\\frac{\\partial h_{1,1}}{\\partial U_{1,1}}$.)"
  },
  {
   "cell_type": "markdown",
   "id": "d9d2baea",
   "metadata": {
    "id": "d9d2baea"
   },
   "source": [
    "By now, hopefully you have got some idea of how PyTorch computes gradients with respect to $\\vect{U}$ by calling a `backward` function on `h11`: the reason is that PyTorch maintains an underlying computation graph, and it can find all ancestors of `h11` (including $\\vect{U}$). The gradient computation process is essentially applying chain rules on this computation graph. (Think of how you would implement it yourself.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b08f5b2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "2b08f5b2"
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## Optional section: RNN backprop on arbitrary sequences\n",
    "\n",
    "> **This section is more challenging in nature and is therefore completely optional and will not affect your grade.**\n",
    "\n",
    "The final challenge! Consider an RNN run on an input sequence of arbitrary length $N$.\n",
    "\n",
    "**Question:** Find a general formula for $\\frac{\\partial L(\\vect{U}, \\vect{V}, \\vect{W}, x_1,\\cdots, x_{N+1}, h_0)}{\\partial \\vect{U}}$ in terms of $\\frac{\\partial L(o_1,\\cdots,o_N, x_2, \\cdots, x_{N+1})}{\\partial o_t}$, $\\frac{\\partial o_t(\\vect{W}, h_t)}{\\partial h_t}$, $\\frac{\\partial h_t(\\vect{U}, \\vect{V}, h_{t-1}, x_t)}{\\partial h_{t-1}}$, and $\\frac{\\partial h_t(\\vect{U}, \\vect{V}, h_{t-1}, x_t)}{\\partial \\vect{U}}$ for $t \\in \\{1, \\ldots, N\\}$.\n",
    "\n",
    "> Hint: How many terms are there when $N$ is 1, 2, or 3? How many possible paths are there from $\\vect{U}$ to $L$ in the computation graph?\n",
    "\n",
    "> Hint: Your solution might look a little like\n",
    "$$ \\sum + \\sum\\left(\\sum\\left(\\prod\\right)\\right) $$\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: open_response_backprop4\n",
    "manual: true\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207c425e",
   "metadata": {},
   "source": "$\\sum_{i=1}^N(\\frac{\\partial L(o_1,o_2,o_3,x_2,x_3,x_{4})}{\\partial o_i} \\cdot \\frac{\\partial o_i(\\vect{W}, h_i)}{\\partial h_i} \\cdot \\sum_{j=1}^i (\\prod_{k=j+1}^i \\frac{\\partial h_k(\\vect{U}, \\vect{V}, h_{k-1}, x_k)}{\\partial h_{k-1}} ) \\cdot \\frac{\\partial h_j(\\vect{U}, \\vect{V}, h_{j-1}, x_j)}{\\partial \\vect{U}}))$"
  },
  {
   "cell_type": "markdown",
   "id": "4bcb9f39",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "4bcb9f39"
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "# Lab debrief\n",
    "\n",
    "**Question:** We're interested in any thoughts you have about this lab so that we can improve this lab for later years, and to inform later labs for this year. Please list any issues that arose or comments you have to improve the lab. Useful things to comment on include the following, but you're not restricted to these:\n",
    "\n",
    "* Was the lab too long or too short?\n",
    "* Were the readings appropriate for the lab?\n",
    "* Was it clear (at least after you completed the lab) what the points of the exercises were?\n",
    "* Are there additions or changes you think would make the lab better?\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: open_response_debrief\n",
    "manual: true\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8588abcc",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3689b6b5",
   "metadata": {
    "id": "3689b6b5"
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "# End of lab 2-2 {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b7d3ef",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "id": "6fbf6cf8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "ExecuteTime": {
     "end_time": "2024-12-11T18:13:46.730565Z",
     "start_time": "2024-12-11T18:13:46.720555Z"
    }
   },
   "source": [
    "grader.check_all()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "automatic_diff:\n",
       "\n",
       "    All tests passed!\n",
       "    \n",
       "\n",
       "bigram:\n",
       "\n",
       "    All tests passed!\n",
       "    \n",
       "\n",
       "forward_by_hand:\n",
       "\n",
       "    All tests passed!\n",
       "    \n",
       "\n",
       "forward_function:\n",
       "\n",
       "    All tests passed!\n",
       "    \n",
       "\n",
       "tiny_bigram_RNN:\n",
       "\n",
       "    All tests passed!\n",
       "    \n"
      ],
      "text/html": [
       "<p><strong>automatic_diff:</strong></p>\n",
       "\n",
       "    \n",
       "    \n",
       "        <p>All tests passed!</p>\n",
       "    \n",
       "    \n",
       "\n",
       "<p><strong>bigram:</strong></p>\n",
       "\n",
       "    \n",
       "    \n",
       "        <p>All tests passed!</p>\n",
       "    \n",
       "    \n",
       "\n",
       "<p><strong>forward_by_hand:</strong></p>\n",
       "\n",
       "    \n",
       "    \n",
       "        <p>All tests passed!</p>\n",
       "    \n",
       "    \n",
       "\n",
       "<p><strong>forward_function:</strong></p>\n",
       "\n",
       "    \n",
       "    \n",
       "        <p>All tests passed!</p>\n",
       "    \n",
       "    \n",
       "\n",
       "<p><strong>tiny_bigram_RNN:</strong></p>\n",
       "\n",
       "    \n",
       "    \n",
       "        <p>All tests passed!</p>\n",
       "    \n",
       "    \n",
       "\n"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "title": "Course 236299 Lab 2-2 – Recurrent neural networks"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
