{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "bf89e409",
      "metadata": {
        "deletable": false,
        "editable": false,
        "execution": {
          "iopub.execute_input": "2025-01-13T08:56:54.536374Z",
          "iopub.status.busy": "2025-01-13T08:56:54.536039Z",
          "iopub.status.idle": "2025-01-13T08:56:55.809900Z",
          "shell.execute_reply": "2025-01-13T08:56:55.808901Z"
        },
        "jupyter": {
          "outputs_hidden": true,
          "source_hidden": true
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bf89e409",
        "outputId": "687bf0ec-2775-4652-d5f2-5ac9c3da5748"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Please do not change this cell because some hidden tests might depend on it.\n",
        "import os\n",
        "\n",
        "# Otter grader does not handle ! commands well, so we define and use our\n",
        "# own function to execute shell commands.\n",
        "def shell(commands, warn=True):\n",
        "    \"\"\"Executes the string `commands` as a sequence of shell commands.\n",
        "\n",
        "       Prints the result to stdout and returns the exit status.\n",
        "       Provides a printed warning on non-zero exit status unless `warn`\n",
        "       flag is unset.\n",
        "    \"\"\"\n",
        "    file = os.popen(commands)\n",
        "    print (file.read().rstrip('\\n'))\n",
        "    exit_status = file.close()\n",
        "    if warn and exit_status != None:\n",
        "        print(f\"Completed with errors. Exit status: {exit_status}\\n\")\n",
        "    return exit_status\n",
        "\n",
        "shell(\"\"\"\n",
        "ls requirements.txt >/dev/null 2>&1\n",
        "if [ ! $? = 0 ]; then\n",
        " rm -rf .tmp\n",
        " git clone https://github.com/cs236299-2024-winter/lab3-3.git .tmp\n",
        " mv .tmp/tests ./\n",
        " mv .tmp/requirements.txt ./\n",
        " rm -rf .tmp\n",
        "fi\n",
        "pip install -q -r requirements.txt\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "5618eee1",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "5618eee1"
      },
      "outputs": [],
      "source": [
        "# Initialize Otter\n",
        "import otter\n",
        "grader = otter.Notebook()"
      ]
    },
    {
      "cell_type": "raw",
      "id": "231868d9",
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "id": "231868d9"
      },
      "source": [
        "%%latex\n",
        "\\newcommand{\\vect}[1]{\\mathbf{#1}}\n",
        "\\newcommand{\\cnt}[1]{\\sharp(#1)}\n",
        "\\newcommand{\\argmax}[1]{\\underset{#1}{\\operatorname{argmax}}}\n",
        "\\newcommand{\\softmax}{\\operatorname{softmax}}\n",
        "\\newcommand{\\Prob}{\\Pr}\n",
        "\\newcommand{\\given}{\\,|\\,}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62f66556",
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "id": "62f66556"
      },
      "source": [
        "$$\n",
        "\\renewcommand{\\vect}[1]{\\mathbf{#1}}\n",
        "\\renewcommand{\\cnt}[1]{\\sharp(#1)}\n",
        "\\renewcommand{\\argmax}[1]{\\underset{#1}{\\operatorname{argmax}}}\n",
        "\\renewcommand{\\softmax}{\\operatorname{softmax}}\n",
        "\\renewcommand{\\Prob}{\\Pr}\n",
        "\\renewcommand{\\given}{\\,|\\,}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2254535",
      "metadata": {
        "id": "a2254535",
        "tags": [
          "remove_for_latex"
        ]
      },
      "source": [
        "# Course 236299\n",
        "## Lab 3-3 - Probabilistic context-free grammars"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5db76bb",
      "metadata": {
        "id": "d5db76bb"
      },
      "source": [
        "In previous labs, you have practiced constituency parsing using context-free grammars with the CKY parsing algorithm. In this lab you will extend this framework to a probabilistic one, probabilistic context-free grammars (PCFG)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0faa586b",
      "metadata": {
        "id": "0faa586b"
      },
      "source": [
        "New bits of Python used for the first time in the _solution set_ for this lab, and which you may therefore find useful:\n",
        "\n",
        "* [`math.prod`](https://docs.python.org/3/library/math.html#math.prod)\n",
        "* [`nltk.tree.Tree.productions`](https://www.nltk.org/api/nltk.html?highlight=production#nltk.tree.Tree.productions)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c57a7941",
      "metadata": {
        "id": "c57a7941"
      },
      "source": [
        "# Preparations {-}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "225b00de",
      "metadata": {
        "deletable": false,
        "editable": false,
        "execution": {
          "iopub.execute_input": "2025-01-13T08:56:55.813858Z",
          "iopub.status.busy": "2025-01-13T08:56:55.813295Z",
          "iopub.status.idle": "2025-01-13T08:56:56.516056Z",
          "shell.execute_reply": "2025-01-13T08:56:56.515288Z"
        },
        "id": "225b00de"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "import math\n",
        "import nltk\n",
        "import operator\n",
        "import pandas as pd\n",
        "\n",
        "from collections import Counter, defaultdict\n",
        "from pprint import pprint"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6b33eef",
      "metadata": {
        "id": "b6b33eef"
      },
      "source": [
        "# Syntactic ambiguity\n",
        "\n",
        "Let's start with the following simplified grammar for arithmetic word expressions from the last lab:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "30726eff",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-01-13T08:56:56.519435Z",
          "iopub.status.busy": "2025-01-13T08:56:56.519150Z",
          "iopub.status.idle": "2025-01-13T08:56:56.523183Z",
          "shell.execute_reply": "2025-01-13T08:56:56.522403Z"
        },
        "id": "30726eff"
      },
      "outputs": [],
      "source": [
        "arithmetic_grammar = nltk.CFG.fromstring(\"\"\"\n",
        "    S -> NUM | S OP S\n",
        "    OP -> ADD | MULT\n",
        "\n",
        "    NUM -> 'zero' | 'one' | 'two' | 'three' | 'four' | 'five'\n",
        "    NUM -> 'six' | 'seven' | 'eight' | 'nine' | 'ten'\n",
        "\n",
        "    ADD -> 'plus'\n",
        "    MULT -> 'times'\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c0f7275",
      "metadata": {
        "id": "7c0f7275"
      },
      "source": [
        "As a running example throughout this lab, we'll use the example phrase \"two times three plus four\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "9ae4fd6f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-01-13T08:56:56.526216Z",
          "iopub.status.busy": "2025-01-13T08:56:56.525774Z",
          "iopub.status.idle": "2025-01-13T08:56:56.529353Z",
          "shell.execute_reply": "2025-01-13T08:56:56.528490Z"
        },
        "id": "9ae4fd6f"
      },
      "outputs": [],
      "source": [
        "example = \"two plus three times four\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab4e3fbf",
      "metadata": {
        "id": "ab4e3fbf"
      },
      "source": [
        "We can use the given CFG to parse this example phrase and print the possible parse trees."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "80f6e746",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-01-13T08:56:56.532552Z",
          "iopub.status.busy": "2025-01-13T08:56:56.531897Z",
          "iopub.status.idle": "2025-01-13T08:56:56.540913Z",
          "shell.execute_reply": "2025-01-13T08:56:56.540143Z"
        },
        "id": "80f6e746",
        "outputId": "2496dca2-1018-4411-f811-002d5cca9b83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parse 1:\n",
            "\n",
            "           S             \n",
            "      _____|__________    \n",
            "     S           |    |  \n",
            "  ___|_____      |    |   \n",
            " S   OP    S     OP   S  \n",
            " |   |     |     |    |   \n",
            "NUM ADD   NUM   MULT NUM \n",
            " |   |     |     |    |   \n",
            "two plus three times four\n",
            "\n",
            "Parse 2:\n",
            "\n",
            "           S             \n",
            "  _________|_____         \n",
            " |   |           S       \n",
            " |   |      _____|____    \n",
            " S   OP    S     OP   S  \n",
            " |   |     |     |    |   \n",
            "NUM ADD   NUM   MULT NUM \n",
            " |   |     |     |    |   \n",
            "two plus three times four\n",
            "\n"
          ]
        }
      ],
      "source": [
        "parser = nltk.parse.BottomUpChartParser(arithmetic_grammar)\n",
        "parses = list(parser.parse(example.split()))\n",
        "\n",
        "for i, tree in enumerate(parses):\n",
        "  print(f\"Parse {i+1}:\\n\")\n",
        "  tree.pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a171202",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "3a171202"
      },
      "source": [
        "Each parse tree represents a structured arithmetic expression. Manually calculate the value of the resulting equation for each of the parse trees.\n",
        "\n",
        "<!--\n",
        "BEGIN QUESTION\n",
        "name: parsed_equation_result\n",
        "-->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "b9e5b4d8",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-01-13T08:56:56.543792Z",
          "iopub.status.busy": "2025-01-13T08:56:56.543590Z",
          "iopub.status.idle": "2025-01-13T08:56:56.547020Z",
          "shell.execute_reply": "2025-01-13T08:56:56.546208Z"
        },
        "id": "b9e5b4d8"
      },
      "outputs": [],
      "source": [
        "#TODO\n",
        "result_tree1 = (2+3)*4 # = 20\n",
        "result_tree2 = 2+(3*4) # = 14"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "0c68a8cc",
      "metadata": {
        "deletable": false,
        "editable": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "0c68a8cc",
        "outputId": "efa1902e-850d-4fae-d43a-1be76208d2aa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "    All tests passed!\n",
              "    "
            ],
            "text/html": [
              "\n",
              "    \n",
              "    \n",
              "        <p>All tests passed!</p>\n",
              "    \n",
              "    "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "grader.check(\"parsed_equation_result\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ecbdcc9",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "4ecbdcc9"
      },
      "source": [
        "We got two different parse trees for this simple expression. The occurrence of different structural interpretations of the same text is called _structural ambiguity_ or _syntactic ambiguity_. Since natural language is oftentimes ambiguous, this is a very real concern.\n",
        "\n",
        "In this particular case, the two syntactic structures corresponded to two different semantic values. As an exercise, try to construct an ambiguous expression (name it `pseudo_ambiguous`) such that all of its parse trees correspond to the same value, thereby demonstrating that not all structural ambiguity leads to semantic ambiguity.\n",
        "\n",
        "<!--\n",
        "BEGIN QUESTION\n",
        "name: redundant_parses\n",
        "-->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "32bfb5e0",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-01-13T08:56:56.575223Z",
          "iopub.status.busy": "2025-01-13T08:56:56.575018Z",
          "iopub.status.idle": "2025-01-13T08:56:56.578382Z",
          "shell.execute_reply": "2025-01-13T08:56:56.577603Z"
        },
        "id": "32bfb5e0"
      },
      "outputs": [],
      "source": [
        "# TODO - construct an ambiguous expression such that all of its parse\n",
        "# trees correspond to the same value. `pseudo_ambiguous` should be\n",
        "# a string.\n",
        "pseudo_ambiguous = 'one times one times one'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "255385c1",
      "metadata": {
        "deletable": false,
        "editable": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "255385c1",
        "outputId": "8cf9ffe7-5a6b-4eeb-de08-5c0d4fd7601a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "    All tests passed!\n",
              "    "
            ],
            "text/html": [
              "\n",
              "    \n",
              "    \n",
              "        <p>All tests passed!</p>\n",
              "    \n",
              "    "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "grader.check(\"redundant_parses\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a5c69c8",
      "metadata": {
        "id": "0a5c69c8"
      },
      "source": [
        "One approach to dealing with the issue of syntactic ambiguity is by defining a scoring system to score the possible parses and choosing the highest scoring tree. We will see how this can be done by taking a probabilistic approach to CFG."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47b4ca61",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "47b4ca61"
      },
      "source": [
        "# Probabilistic context-free grammars\n",
        "\n",
        "To assign probabilities to strings, we will use a probabilistic context-free grammar (PCFG), a CFG in which each rule is augmented with a probability. A PCFG rule will be notated\n",
        "$$A \\to \\beta\\ [p]$$\n",
        "where $A$ is a nonterminal, $\\beta$ is a sequence of terminals and nonterminals, and $p$ is a probability associated with the rule.\n",
        "\n",
        "We'll write $\\Prob(\\beta \\given A)$ for the probability associated with the rule $A \\to \\beta$.\n",
        "\n",
        "To constitute a valid probability distribution we require that for every nonterminal $A$\n",
        "$$\\sum_{A \\to \\beta \\in {G}} \\Prob(\\beta \\given A) = 1$$\n",
        "where ${G}$ is the set of CFG productions of the grammar. That is, the probabilities associated with all rules with the same left-hand side must sum to one.\n",
        "\n",
        "Define `probabilistic_arithmetic_grammar` to be a probabilistic version of `arithmetic grammar` above, where the nonterminal probability distributions are **as uniform across the productions as possible**. Round the probabilities up to 4 decimal digits.\n",
        "\n",
        "> You'll use the NLTK `nltk.PCFG.fromstring` function, which allows you to add the probabilities in brackets after each right-hand side, just as we've been doing above. For example, to notate `NUM -> 'zero'` as of probability 0.5, use `NUM -> 'zero' [0.5]`.\n",
        "\n",
        "<!--\n",
        "BEGIN QUESTION\n",
        "name: uniform_probabilities\n",
        "-->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "370bc7f6",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-01-13T08:56:56.612312Z",
          "iopub.status.busy": "2025-01-13T08:56:56.612097Z",
          "iopub.status.idle": "2025-01-13T08:56:56.616235Z",
          "shell.execute_reply": "2025-01-13T08:56:56.615466Z"
        },
        "id": "370bc7f6"
      },
      "outputs": [],
      "source": [
        "# TODO - define `probabilistic_arithmetic_grammar`. Round to\n",
        "#        *3* significant figures if not divisible.\n",
        "probabilistic_arithmetic_grammar = nltk.PCFG.fromstring('''\n",
        "    S -> NUM [0.5]\n",
        "    S -> S OP S [0.5]\n",
        "\n",
        "    OP -> ADD [0.5]\n",
        "    OP -> MULT [0.5]\n",
        "\n",
        "    NUM -> 'zero' [0.0909]\n",
        "    NUM -> 'one' [0.0909]\n",
        "    NUM -> 'two' [0.0909]\n",
        "    NUM -> 'three' [0.0909]\n",
        "    NUM -> 'four' [0.0909]\n",
        "    NUM -> 'five' [0.0909]\n",
        "    NUM -> 'six' [0.0909]\n",
        "    NUM -> 'seven' [0.0909]\n",
        "    NUM -> 'eight' [0.0909]\n",
        "    NUM -> 'nine' [0.0909]\n",
        "    NUM -> 'ten' [0.0909]\n",
        "\n",
        "    ADD -> 'plus' [1]\n",
        "    MULT -> 'times' [1]\n",
        "''')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "dd8e5231",
      "metadata": {
        "deletable": false,
        "editable": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "dd8e5231",
        "outputId": "4b45a1c1-14d9-4b2e-cb43-60ffecdb2777"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "    All tests passed!\n",
              "    "
            ],
            "text/html": [
              "\n",
              "    \n",
              "    \n",
              "        <p>All tests passed!</p>\n",
              "    \n",
              "    "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "grader.check(\"uniform_probabilities\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a91f5da7",
      "metadata": {
        "id": "a91f5da7"
      },
      "source": [
        "We can use the [nltk.CFG.productions()](https://www.nltk.org/api/nltk.html?highlight=production#nltk.grammar.CFG.productions) method to get a list of the PCFG's productions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "21f544e5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-01-13T08:56:56.642790Z",
          "iopub.status.busy": "2025-01-13T08:56:56.642575Z",
          "iopub.status.idle": "2025-01-13T08:56:56.647882Z",
          "shell.execute_reply": "2025-01-13T08:56:56.647023Z"
        },
        "id": "21f544e5",
        "outputId": "f4516564-bdf9-4257-9624-9044300a93c1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[S -> NUM [0.5],\n",
              " S -> S OP S [0.5],\n",
              " OP -> ADD [0.5],\n",
              " OP -> MULT [0.5],\n",
              " NUM -> 'zero' [0.0909],\n",
              " NUM -> 'one' [0.0909],\n",
              " NUM -> 'two' [0.0909],\n",
              " NUM -> 'three' [0.0909],\n",
              " NUM -> 'four' [0.0909],\n",
              " NUM -> 'five' [0.0909],\n",
              " NUM -> 'six' [0.0909],\n",
              " NUM -> 'seven' [0.0909],\n",
              " NUM -> 'eight' [0.0909],\n",
              " NUM -> 'nine' [0.0909],\n",
              " NUM -> 'ten' [0.0909],\n",
              " ADD -> 'plus' [1.0],\n",
              " MULT -> 'times' [1.0]]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "probabilistic_arithmetic_grammar.productions()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16ba1978",
      "metadata": {
        "id": "16ba1978"
      },
      "source": [
        "Each of the productions in the list is an instance of the [ProbabilisticProduction](https://www.nltk.org/api/nltk.html?highlight=production#nltk.grammar.ProbabilisticProduction) class. Each such instance is defined by three parameters: its left hand side (`lhs`), right-hand side (`rhs`), and rule probability (`prob`). These attributes can be accessed separately:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "a8833274",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-01-13T08:56:56.650667Z",
          "iopub.status.busy": "2025-01-13T08:56:56.650440Z",
          "iopub.status.idle": "2025-01-13T08:56:56.654888Z",
          "shell.execute_reply": "2025-01-13T08:56:56.653977Z"
        },
        "id": "a8833274",
        "outputId": "098243af-15e8-45f8-f19f-f085dc68603e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For the production \"S -> S OP S [0.5]\":\n",
            "left hand side of the rule is S\n",
            "right hand side of the rule is (S, OP, S)\n",
            "probability of the rule is 0.5\n"
          ]
        }
      ],
      "source": [
        "## Extract the second rule\n",
        "pprod_example = probabilistic_arithmetic_grammar.productions()[1]\n",
        "\n",
        "## Display its various components\n",
        "print(f'For the production \"{pprod_example}\":\\n'\n",
        "      f'left hand side of the rule is {pprod_example.lhs()}\\n'\n",
        "      f'right hand side of the rule is {pprod_example.rhs()}\\n'\n",
        "      f'probability of the rule is {pprod_example.prob()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2dff3c2b",
      "metadata": {
        "id": "2dff3c2b"
      },
      "source": [
        "For non-probabilistic grammars, the class of productions is [Production](https://www.nltk.org/api/nltk.html?highlight=production#nltk.grammar.Production), which doesn't have a probability attribute and is only defined by its lhs and rhs attributes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "4634204d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-01-13T08:56:56.657776Z",
          "iopub.status.busy": "2025-01-13T08:56:56.657565Z",
          "iopub.status.idle": "2025-01-13T08:56:56.661705Z",
          "shell.execute_reply": "2025-01-13T08:56:56.660805Z"
        },
        "id": "4634204d",
        "outputId": "376afe3c-2d22-4089-a19b-753bb4671a2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PCFG production: S -> S OP S [0.5] \n",
            "      vs.\n",
            "CFG production:  S -> S OP S\n"
          ]
        }
      ],
      "source": [
        "print(f'PCFG production: {probabilistic_arithmetic_grammar.productions()[1]} \\n'\n",
        "      f'      vs.\\n'\n",
        "      f'CFG production:  {arithmetic_grammar.productions()[1]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc7f581b",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "dc7f581b"
      },
      "source": [
        "# Parse tree probabilities\n",
        "\n",
        "To use a PCFG to select among parse trees, we need to be able to calculate the probability of a parse tree as specified by the PCFG. We take the probability of a parse tree to be simply the product of the probabilities of each constituent in the tree, the probability of the rule associated with the constituent.\n",
        "\n",
        "You'll use the PCFG `probabilistic_arithmetic_grammar` to calculate the probability of each of the parse trees in `parses`, the list of trees that were parsed from the `example` sentence.\n",
        "\n",
        "To do that, you'll need to get all the productions used in a parse tree (using the [productions](https://www.nltk.org/api/nltk.html?highlight=production#nltk.tree.Tree.productions) method), find their probabilities, and multiply them together.\n",
        "\n",
        "First, we will create a dictionary from the PCFG, so that we can easily access the rule probabilities. Write a function which accepts a PCFG and returns a dictionary whose keys are the CFG (not PCFG) productions and values are the associated probabilities.\n",
        "\n",
        "> To construct a CFG production from a PCFG production, you can use `nltk.grammar.Production(production.lhs(), production.rhs())`.\n",
        "\n",
        "<!--\n",
        "BEGIN QUESTION\n",
        "name: pcfg_to_dict\n",
        "-->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "47c0bb2e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-01-13T08:56:56.664811Z",
          "iopub.status.busy": "2025-01-13T08:56:56.664602Z",
          "iopub.status.idle": "2025-01-13T08:56:56.668498Z",
          "shell.execute_reply": "2025-01-13T08:56:56.667633Z"
        },
        "id": "47c0bb2e"
      },
      "outputs": [],
      "source": [
        "#TODO - returns a dictionary whose keys are `nltk.grammar.Production` objects\n",
        "#       and whose values are the associated probabilities\n",
        "def pcfg_to_dict(pcfg):\n",
        "  pcfg_dict = {}\n",
        "  for production in pcfg.productions():\n",
        "    pcfg_dict[nltk.grammar.Production(production.lhs(), production.rhs())] = production.prob()\n",
        "  return pcfg_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "610602c0",
      "metadata": {
        "deletable": false,
        "editable": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "610602c0",
        "outputId": "ec80b8fa-1b18-44f9-f302-2241d61a5165"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "    All tests passed!\n",
              "    "
            ],
            "text/html": [
              "\n",
              "    \n",
              "    \n",
              "        <p>All tests passed!</p>\n",
              "    \n",
              "    "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "grader.check(\"pcfg_to_dict\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b862e16",
      "metadata": {
        "id": "0b862e16"
      },
      "source": [
        "We can use the function you wrote to convert `probabilistic_arithmetic_grammar` to a dictionary and inspect it to make sure it's working."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "28df0fd2",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-01-13T08:56:56.695737Z",
          "iopub.status.busy": "2025-01-13T08:56:56.695527Z",
          "iopub.status.idle": "2025-01-13T08:56:56.700186Z",
          "shell.execute_reply": "2025-01-13T08:56:56.699289Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28df0fd2",
        "outputId": "b58e6d45-1b10-4b62-c418-41957b3b7e53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{ADD -> 'plus': 1.0,\n",
            " MULT -> 'times': 1.0,\n",
            " NUM -> 'eight': 0.0909,\n",
            " NUM -> 'five': 0.0909,\n",
            " NUM -> 'four': 0.0909,\n",
            " NUM -> 'nine': 0.0909,\n",
            " NUM -> 'one': 0.0909,\n",
            " NUM -> 'seven': 0.0909,\n",
            " NUM -> 'six': 0.0909,\n",
            " NUM -> 'ten': 0.0909,\n",
            " NUM -> 'three': 0.0909,\n",
            " NUM -> 'two': 0.0909,\n",
            " NUM -> 'zero': 0.0909,\n",
            " OP -> ADD: 0.5,\n",
            " OP -> MULT: 0.5,\n",
            " S -> NUM: 0.5,\n",
            " S -> S OP S: 0.5}\n"
          ]
        }
      ],
      "source": [
        "pprint(pcfg_to_dict(probabilistic_arithmetic_grammar))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac0ac680",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "ac0ac680"
      },
      "source": [
        "Now for the payoff: Write a function that takes a parse tree and a PCFG and returns the probability of the parse tree according to the PCFG. The `pcfg_to_dict` function you just wrote is likely to come in handy.\n",
        "\n",
        "> Note that we are asking for the probability (not the log probability). We **don't work in log space** in this lab for simplicity, but for parse trees of longer sentences (which you'll see in the project) you might have to work in the log space to avoid underflows.\n",
        "\n",
        "<!--\n",
        "BEGIN QUESTION\n",
        "name: parsed_trees_probs\n",
        "-->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "7c875885",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-01-13T08:56:56.703289Z",
          "iopub.status.busy": "2025-01-13T08:56:56.703087Z",
          "iopub.status.idle": "2025-01-13T08:56:56.706913Z",
          "shell.execute_reply": "2025-01-13T08:56:56.706090Z"
        },
        "id": "7c875885"
      },
      "outputs": [],
      "source": [
        "# TODO: returns the probability of the parse tree.\n",
        "# `tree.productions() might be useful for getting the\n",
        "#  productions of a parse tree\n",
        "def parse_probability(tree, pcfg):\n",
        "    pcfg_dict = pcfg_to_dict(pcfg)\n",
        "    prob = 1\n",
        "    for production in tree.productions():\n",
        "        prob *= pcfg_dict[nltk.grammar.Production(production.lhs(), production.rhs())]\n",
        "    return prob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "5cde7dff",
      "metadata": {
        "deletable": false,
        "editable": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "5cde7dff",
        "outputId": "7ef0e413-5044-400d-b75a-1b4f472f836c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "    All tests passed!\n",
              "    "
            ],
            "text/html": [
              "\n",
              "    \n",
              "    \n",
              "        <p>All tests passed!</p>\n",
              "    \n",
              "    "
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "grader.check(\"parsed_trees_probs\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c558256",
      "metadata": {
        "id": "8c558256"
      },
      "source": [
        "We'll use it to calculate and print out the probability of each parse tree."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "6bce73fd",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-01-13T08:56:56.724620Z",
          "iopub.status.busy": "2025-01-13T08:56:56.724386Z",
          "iopub.status.idle": "2025-01-13T08:56:56.730536Z",
          "shell.execute_reply": "2025-01-13T08:56:56.729631Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bce73fd",
        "outputId": "5d0200cc-593d-4d0b-e2f1-052943f7bbd5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Probability of parse tree 1 is 5.87e-06\n",
            "           S             \n",
            "      _____|__________    \n",
            "     S           |    |  \n",
            "  ___|_____      |    |   \n",
            " S   OP    S     OP   S  \n",
            " |   |     |     |    |   \n",
            "NUM ADD   NUM   MULT NUM \n",
            " |   |     |     |    |   \n",
            "two plus three times four\n",
            "\n",
            "Probability of parse tree 2 is 5.87e-06\n",
            "           S             \n",
            "  _________|_____         \n",
            " |   |           S       \n",
            " |   |      _____|____    \n",
            " S   OP    S     OP   S  \n",
            " |   |     |     |    |   \n",
            "NUM ADD   NUM   MULT NUM \n",
            " |   |     |     |    |   \n",
            "two plus three times four\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for i, tree in enumerate(parses):\n",
        "    print(f'Probability of parse tree {i+1} is '\n",
        "          f'{parse_probability(tree, probabilistic_arithmetic_grammar):1.2e}')\n",
        "    tree.pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4624056f",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "4624056f"
      },
      "source": [
        "<!-- BEGIN QUESTION -->\n",
        "\n",
        "**Question:** Which of the trees is the most probable parse? Explain why. If the two have the same probability, explain why that is the case instead, and describe how you might adjust the rule probabilities if possible so that they have different probabilities.\n",
        "\n",
        "<!--\n",
        "BEGIN QUESTION\n",
        "name: open_response_ambiguity\n",
        "manual: true\n",
        "-->"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d5fef8d",
      "metadata": {
        "id": "1d5fef8d"
      },
      "source": [
        "Both trees have the same probability (5.87e-06). This is the case because the trees only differ in the order of the productions (and thus, in the structure of the tree) but they do not differ in the content of the productions sets themselves. Since both trees have the same set of productions, and each production has a single constant probability, the overall probabilities of the trees are equal. In line with this, it is impossible to change the probabilities of the trees simply by changing the probabilities of the rules. To get different probabilities of the trees we will have to make other changes such as changing the grammer, or setting the probabilities while taking the context into account etc."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e13bd1e",
      "metadata": {
        "id": "3e13bd1e"
      },
      "source": [
        "<!-- END QUESTION -->\n",
        "\n",
        "\n",
        "\n",
        "# Lexicalizing the grammar\n",
        "\n",
        "In order to allow parse probabilities to be more sensitive to contexts, it turns out to be useful to _lexicalize_ the grammar -- splitting (some of the) nonterminals based on what particular words they dominate. There are many techniques for performing this lexicalization. For this grammar, we'll split the `S` nonterminal based on the main operator that it dominates (if any). We'll thus have nonterminals `S_ADD`, `S_MULT`, and `S_NUM`. Thus, instead of a rule `S -> S OP S`, we'll have rules like:\n",
        "\n",
        "```\n",
        "S_ADD -> S_NUM ADD S_NUM\n",
        "S_ADD -> S_NUM ADD S_ADD\n",
        "S_ADD -> S_NUM ADD S_MULT\n",
        "S_ADD -> S_ADD ADD S_NUM\n",
        "```\n",
        "and so forth. By splitting the nonterminals (and hence the productions) in this way, we can assign different probabilities to cases where, for instance, the primary operator on the left is a number, or addition, or multiplication.\n",
        "\n",
        "Here is the lexicalized grammar:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "2f17b7a0",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-01-13T08:56:56.733582Z",
          "iopub.status.busy": "2025-01-13T08:56:56.733370Z",
          "iopub.status.idle": "2025-01-13T08:56:56.737956Z",
          "shell.execute_reply": "2025-01-13T08:56:56.737088Z"
        },
        "id": "2f17b7a0"
      },
      "outputs": [],
      "source": [
        "lexicalized_arithmetic_grammar = nltk.CFG.fromstring(\n",
        "    \"\"\"\n",
        "    S -> S_NUM | S_ADD | S_MULT\n",
        "\n",
        "    S_NUM -> NUM\n",
        "\n",
        "    S_ADD -> S_NUM ADD S_NUM\n",
        "    S_ADD -> S_NUM ADD S_ADD\n",
        "    S_ADD -> S_NUM ADD S_MULT\n",
        "    S_ADD -> S_ADD ADD S_NUM\n",
        "    S_ADD -> S_ADD ADD S_ADD\n",
        "    S_ADD -> S_ADD ADD S_MULT\n",
        "    S_ADD -> S_MULT ADD S_NUM\n",
        "    S_ADD -> S_MULT ADD S_ADD\n",
        "    S_ADD -> S_MULT ADD S_MULT\n",
        "\n",
        "    S_MULT -> S_NUM MULT S_NUM\n",
        "    S_MULT -> S_NUM MULT S_ADD\n",
        "    S_MULT -> S_NUM MULT S_MULT\n",
        "    S_MULT -> S_ADD MULT S_NUM\n",
        "    S_MULT -> S_ADD MULT S_ADD\n",
        "    S_MULT -> S_ADD MULT S_MULT\n",
        "    S_MULT -> S_MULT MULT S_NUM\n",
        "    S_MULT -> S_MULT MULT S_ADD\n",
        "    S_MULT -> S_MULT MULT S_MULT\n",
        "\n",
        "    NUM -> 'zero'   | 'one'    | 'two'\n",
        "    NUM -> 'three'  | 'four'   | 'five'\n",
        "    NUM -> 'six'    | 'seven'  | 'eight'\n",
        "    NUM -> 'nine'   | 'ten'\n",
        "\n",
        "    ADD -> 'plus'\n",
        "    MULT -> 'times'\n",
        "    \"\"\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f7eefc5",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "9f7eefc5"
      },
      "source": [
        "<!-- BEGIN QUESTION -->\n",
        "\n",
        "Use this grammar to parse the example phrase (\"two plus three times four\") defined as `example` above.\n",
        "\n",
        "<!--\n",
        "BEGIN QUESTION\n",
        "name: lexicalized_parse\n",
        "manual: true\n",
        "-->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "aa8a4d34",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-01-13T08:56:56.740983Z",
          "iopub.status.busy": "2025-01-13T08:56:56.740779Z",
          "iopub.status.idle": "2025-01-13T08:56:56.747717Z",
          "shell.execute_reply": "2025-01-13T08:56:56.746852Z"
        },
        "id": "aa8a4d34"
      },
      "outputs": [],
      "source": [
        "# TODO - parse `example` using the lexicalized grammar. `lexicalized_parses`\n",
        "#        should be a list of parses.\n",
        "lexicalized_parser = nltk.parse.BottomUpChartParser(lexicalized_arithmetic_grammar)\n",
        "lexicalized_parses = list(lexicalized_parser.parse(example.split()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "cf171f0a",
      "metadata": {
        "deletable": false,
        "editable": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "cf171f0a",
        "outputId": "32195121-d19e-4854-fe32-179f420aec8d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "    All tests passed!\n",
              "    "
            ],
            "text/html": [
              "\n",
              "    \n",
              "    \n",
              "        <p>All tests passed!</p>\n",
              "    \n",
              "    "
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "grader.check(\"lexicalized_parse\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf5ec0bb",
      "metadata": {
        "id": "bf5ec0bb"
      },
      "source": [
        "<!-- END QUESTION -->\n",
        "\n",
        "\n",
        "\n",
        "Examine the trees, and make sure that you understand why they look the way they do. Notice that because of the lexicalization, the highest `S_` node corresponds to the highest operator in the parse -- `S_MULT` when `MULT` is the highest operator and `S_ADD` when `ADD` is the highest operator."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "fd654c2a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-01-13T08:56:56.765994Z",
          "iopub.status.busy": "2025-01-13T08:56:56.765774Z",
          "iopub.status.idle": "2025-01-13T08:56:56.771603Z",
          "shell.execute_reply": "2025-01-13T08:56:56.770728Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fd654c2a",
        "outputId": "5e48231a-03d4-424a-e297-b70d20acef19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Possible parse 1:\n",
            "\n",
            "              S               \n",
            "              |                \n",
            "            S_MULT            \n",
            "         _____|____________    \n",
            "      S_ADD          |     |  \n",
            "   _____|_____       |     |   \n",
            "S_NUM   |   S_NUM    |   S_NUM\n",
            "  |     |     |      |     |   \n",
            " NUM   ADD   NUM    MULT  NUM \n",
            "  |     |     |      |     |   \n",
            " two   plus three  times  four\n",
            "\n",
            "Possible parse 2:\n",
            "\n",
            "             S               \n",
            "             |                \n",
            "           S_ADD             \n",
            "   __________|_____           \n",
            "  |    |         S_MULT      \n",
            "  |    |      _____|______    \n",
            "S_NUM  |   S_NUM   |    S_NUM\n",
            "  |    |     |     |      |   \n",
            " NUM  ADD   NUM   MULT   NUM \n",
            "  |    |     |     |      |   \n",
            " two  plus three times   four\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for i, tree in enumerate(lexicalized_parses):\n",
        "  print(f\"Possible parse {i+1}:\\n\")\n",
        "  tree.pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "061d558e",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "061d558e"
      },
      "source": [
        "We can augment this grammar with probabilities as well.\n",
        "\n",
        "Again, do so **making the probabilities for rules with the same left-hand side as uniform as possible**.\n",
        "<!--\n",
        "BEGIN QUESTION\n",
        "name: uniform_lexicalized_probabilities\n",
        "-->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "993a0d49",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-01-13T08:56:56.774549Z",
          "iopub.status.busy": "2025-01-13T08:56:56.774336Z",
          "iopub.status.idle": "2025-01-13T08:56:56.779394Z",
          "shell.execute_reply": "2025-01-13T08:56:56.778516Z"
        },
        "id": "993a0d49"
      },
      "outputs": [],
      "source": [
        "# TODO - define `probabilistic_lexicalized_arithmetic_grammar`.\n",
        "#        Round to *3* significant figures if not divisible.\n",
        "probabilistic_lexicalized_arithmetic_grammar = nltk.PCFG.fromstring('''\n",
        "    S -> S_NUM  [0.3333]\n",
        "    S -> S_ADD [0.3333]\n",
        "    S -> S_MULT [0.3333]\n",
        "\n",
        "    S_NUM -> NUM [1]\n",
        "\n",
        "    S_ADD -> S_NUM ADD S_NUM [0.1111]\n",
        "    S_ADD -> S_NUM ADD S_ADD [0.1111]\n",
        "    S_ADD -> S_NUM ADD S_MULT [0.1111]\n",
        "    S_ADD -> S_ADD ADD S_NUM [0.1111]\n",
        "    S_ADD -> S_ADD ADD S_ADD [0.1111]\n",
        "    S_ADD -> S_ADD ADD S_MULT [0.1111]\n",
        "    S_ADD -> S_MULT ADD S_NUM [0.1111]\n",
        "    S_ADD -> S_MULT ADD S_ADD [0.1111]\n",
        "    S_ADD -> S_MULT ADD S_MULT [0.1111]\n",
        "\n",
        "    S_MULT -> S_NUM MULT S_NUM  [0.1111]\n",
        "    S_MULT -> S_NUM MULT S_ADD [0.1111]\n",
        "    S_MULT -> S_NUM MULT S_MULT [0.1111]\n",
        "    S_MULT -> S_ADD MULT S_NUM [0.1111]\n",
        "    S_MULT -> S_ADD MULT S_ADD [0.1111]\n",
        "    S_MULT -> S_ADD MULT S_MULT [0.1111]\n",
        "    S_MULT -> S_MULT MULT S_NUM [0.1111]\n",
        "    S_MULT -> S_MULT MULT S_ADD [0.1111]\n",
        "    S_MULT -> S_MULT MULT S_MULT [0.1111]\n",
        "\n",
        "    NUM -> 'zero' [0.0909]\n",
        "    NUM -> 'one' [0.0909]\n",
        "    NUM -> 'two' [0.0909]\n",
        "    NUM -> 'three' [0.0909]\n",
        "    NUM -> 'four' [0.0909]\n",
        "    NUM -> 'five' [0.0909]\n",
        "    NUM -> 'six' [0.0909]\n",
        "    NUM -> 'seven' [0.0909]\n",
        "    NUM -> 'eight' [0.0909]\n",
        "    NUM -> 'nine' [0.0909]\n",
        "    NUM -> 'ten' [0.0909]\n",
        "\n",
        "    ADD -> 'plus' [1]\n",
        "    MULT -> 'times' [1]\n",
        "''')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "f8899502",
      "metadata": {
        "deletable": false,
        "editable": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "f8899502",
        "outputId": "3a403738-cc1e-45e5-f72a-86e9abc4d003"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "    All tests passed!\n",
              "    "
            ],
            "text/html": [
              "\n",
              "    \n",
              "    \n",
              "        <p>All tests passed!</p>\n",
              "    \n",
              "    "
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "grader.check(\"uniform_lexicalized_probabilities\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90426670",
      "metadata": {
        "id": "90426670"
      },
      "source": [
        "Using this PCFG, we can calculate the probabilities associated with the two parses of the example phrase."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "b0b883ff",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-01-13T08:56:56.805784Z",
          "iopub.status.busy": "2025-01-13T08:56:56.805570Z",
          "iopub.status.idle": "2025-01-13T08:56:56.812009Z",
          "shell.execute_reply": "2025-01-13T08:56:56.811119Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0b883ff",
        "outputId": "1fbf4181-e8a2-4ce5-c8be-6920d91a94de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Probability of parsed tree 1 is 3.09e-06\n",
            "              S               \n",
            "              |                \n",
            "            S_MULT            \n",
            "         _____|____________    \n",
            "      S_ADD          |     |  \n",
            "   _____|_____       |     |   \n",
            "S_NUM   |   S_NUM    |   S_NUM\n",
            "  |     |     |      |     |   \n",
            " NUM   ADD   NUM    MULT  NUM \n",
            "  |     |     |      |     |   \n",
            " two   plus three  times  four\n",
            "\n",
            "Probability of parsed tree 2 is 3.09e-06\n",
            "             S               \n",
            "             |                \n",
            "           S_ADD             \n",
            "   __________|_____           \n",
            "  |    |         S_MULT      \n",
            "  |    |      _____|______    \n",
            "S_NUM  |   S_NUM   |    S_NUM\n",
            "  |    |     |     |      |   \n",
            " NUM  ADD   NUM   MULT   NUM \n",
            "  |    |     |     |      |   \n",
            " two  plus three times   four\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for i, tree in enumerate(lexicalized_parses):\n",
        "    print(f'Probability of parsed tree {i+1} is '\n",
        "          f'{parse_probability(tree, probabilistic_lexicalized_arithmetic_grammar):1.2e}')\n",
        "    tree.pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9dbe66b",
      "metadata": {
        "id": "c9dbe66b"
      },
      "source": [
        "Make sure that you understand why the parse probabilities are the way they are. Why do they differ from the probabilities for the corresponding trees of the previous grammar? Why do the two trees still have the same probability?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ddcf498f",
      "metadata": {
        "id": "ddcf498f"
      },
      "source": [
        "# Estimating rule probabilities from a corpus\n",
        "\n",
        "In the previous section, you received a CFG augmented with rule probabilities that were arbitrarily stipulated. But where should rule probabilities come from? One way to generate rule probabilites is to learn them from a training corpus.\n",
        "\n",
        "In this section you will use a toy corpus of sentences parsed according to the lexicalized grammar to generate maximum likelihood estimates of rule probabilities by counting the number of occurrences of a rule used in the corpus."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "b26fd726",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-01-13T08:56:56.815107Z",
          "iopub.status.busy": "2025-01-13T08:56:56.814902Z",
          "iopub.status.idle": "2025-01-13T08:56:56.820059Z",
          "shell.execute_reply": "2025-01-13T08:56:56.819220Z"
        },
        "id": "b26fd726"
      },
      "outputs": [],
      "source": [
        "## The raw corpus, before splitting into separate phrases\n",
        "corpus_raw = \"\"\"\n",
        "    # seven\n",
        "    (S (S_NUM (NUM seven)))\n",
        "    # one plus two\n",
        "    (S (S_ADD (S_NUM (NUM one)) (ADD plus) (S_NUM (NUM two))))\n",
        "    # two times three\n",
        "    (S (S_MULT (S_NUM (NUM two)) (MULT times) (S_NUM (NUM three))))\n",
        "    # two plus six times one\n",
        "    (S (S_ADD (S_NUM (NUM two)) (ADD plus) (S_MULT (S_NUM (NUM six)) (MULT times) (S_NUM (NUM one)))))\n",
        "    # eight plus three plus seven\n",
        "    (S (S_ADD (S_ADD (S_NUM (NUM eight)) (ADD plus) (S_NUM (NUM three))) (ADD plus) (S_NUM (NUM seven))))\n",
        "    # two plus three times four\n",
        "    (S (S_ADD (S_NUM (NUM two)) (ADD plus) (S_MULT (S_NUM (NUM three)) (MULT times) (S_NUM (NUM four)))))\n",
        "    # eight times four times two\n",
        "    (S (S_MULT (S_MULT (S_NUM (NUM eight)) (MULT times) (S_NUM (NUM four))) (MULT times) (S_NUM (NUM two))))\n",
        "    # five times two plus one\n",
        "    (S (S_ADD (S_MULT (S_NUM (NUM five)) (MULT times) (S_NUM (NUM two))) (ADD plus) (S_NUM (NUM one))))\n",
        "    # five plus one times four\n",
        "    (S (S_ADD (S_NUM (NUM five)) (ADD plus) (S_MULT (S_NUM (NUM one)) (MULT times) (S_NUM (NUM four)))))\n",
        "    # two times three plus four\n",
        "    (S (S_ADD (S_MULT (S_NUM (NUM two)) (MULT times) (S_NUM (NUM three))) (ADD plus) (S_NUM (NUM four))))\n",
        "    # ten plus two times three\n",
        "    (S (S_ADD (S_NUM (NUM ten)) (ADD plus) (S_MULT (S_NUM (NUM two)) (MULT times) (S_NUM (NUM three)))))\n",
        "    # four times three plus two times one\n",
        "    (S (S_ADD (S_MULT (S_NUM (NUM four)) (MULT times) (S_NUM (NUM three))) (ADD plus) (S_MULT (S_NUM (NUM two)) (MULT times) (S_NUM (NUM one)))))\n",
        "    # four plus three times two plus one\n",
        "    (S (S_ADD (S_ADD (S_NUM (NUM four)) (ADD plus) (S_MULT (S_NUM (NUM three)) (MULT times) (S_NUM (NUM two)))) (ADD plus) (S_NUM (NUM one))))\n",
        "\"\"\"\n",
        "\n",
        "def corpus_from_string(raw):\n",
        "  \"\"\"Return a corpus as a list of sentences.\n",
        "\n",
        "  The `raw` corpus is split at newlines, trimmed of whitespace,\n",
        "  and comment lines and blank lines are eliminated.\n",
        "  \"\"\"\n",
        "  return list(filter(lambda x: x != '' and x[0] != '#',\n",
        "                     map(lambda sent: sent.strip(),\n",
        "                         raw.split('\\n'))))\n",
        "\n",
        "## The processed corpus we'll use\n",
        "corpus = corpus_from_string(corpus_raw)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "077674ff",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "077674ff"
      },
      "source": [
        "Recall that for the rule probabilities to define a valid probability distibution, the following needs to hold\n",
        "$$\\sum_{A \\to \\beta \\in G} \\Prob(\\beta \\given A) = 1$$\n",
        "where $G$ is the set of productions.\n",
        "\n",
        "In order to get an estimate for each production probability, we can count the number of occurrences of the production, normalizing by the number of occurrences of all productions with the same left-hand side.\n",
        "\n",
        "\\begin{align}\n",
        "\\Prob(\\beta \\given A)\n",
        "  &= \\frac{\\cnt{A \\to \\beta}}{\\sum_{\\beta'} \\cnt{A \\to \\beta'}} \\\\\n",
        "  &= \\frac{\\cnt{A \\to \\beta}}{\\cnt{A}}\n",
        "\\end{align}\n",
        "\n",
        "We will define three functions:\n",
        "\n",
        "1. `rule_counter` - Accepts a list of sentences and returns a dictionary of rule counts (where the key is the NLTK CFG production (defined by the lhs and rhs) and the value is the number of rule occurrences).\n",
        "2. `lhs_counter` - Accepts a list of sentences and returns a dictionary of lhs counts (where the key is the lhs nonterminal and the value is the count of that nonterminal's occurences as a lhs).\n",
        "3. `rule_probs` - Accepts a CFG and a list of sentences and returns a PCFG with probabilities based on the training corpus; assumes that the parses in the corpus are consistent with the CFG argument.\n",
        "\n",
        "Implement these functions as specified above.\n",
        "\n",
        "> **Hint:** The following NLTK functions may be useful:\n",
        ">\n",
        "> * `nltk.Tree.fromstring`\n",
        "> * `nltk.grammar.PCFG`\n",
        "> * `nltk.grammar.productions`\n",
        "> * `nltk.grammar.ProbabilisticProduction`\n",
        "\n",
        "<!--\n",
        "BEGIN QUESTION\n",
        "name: probs_from_corpus\n",
        "-->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "486f479e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-01-13T08:56:56.822934Z",
          "iopub.status.busy": "2025-01-13T08:56:56.822719Z",
          "iopub.status.idle": "2025-01-13T08:56:56.829184Z",
          "shell.execute_reply": "2025-01-13T08:56:56.828314Z"
        },
        "id": "486f479e"
      },
      "outputs": [],
      "source": [
        "#TODO\n",
        "def rule_counter(sentence_list):\n",
        "  counter_dict = defaultdict(lambda: defaultdict(int))\n",
        "  for sentence in sentence_list:\n",
        "    tree = nltk.Tree.fromstring(sentence)\n",
        "    for production in tree.productions():\n",
        "      if (production.lhs() in counter_dict) and (production.rhs() in counter_dict[production.lhs()]):\n",
        "        counter_dict[production.lhs()][production.rhs()] += 1\n",
        "      else:\n",
        "        counter_dict[production.lhs()][production.rhs()] = 1\n",
        "  return counter_dict\n",
        "\n",
        "#TODO\n",
        "def lhs_counter(sentence_list):\n",
        "  counter_dict = {}\n",
        "  for sentence in sentence_list:\n",
        "    tree = nltk.Tree.fromstring(sentence)\n",
        "    for production in tree.productions():\n",
        "      if production.lhs() in counter_dict:\n",
        "        counter_dict[production.lhs()] += 1\n",
        "      else:\n",
        "        counter_dict[production.lhs()] = 1\n",
        "  return counter_dict\n",
        "\n",
        "#TODO\n",
        "def train_pcfg(cfg, sentence_list):\n",
        "  rule_counter_dict = rule_counter(sentence_list)\n",
        "  lhs_counter_dict = lhs_counter(sentence_list)\n",
        "  prob_production_list = []\n",
        "  for production in cfg.productions():\n",
        "    if (production.lhs() in rule_counter_dict) and (production.rhs() in rule_counter_dict[production.lhs()]):\n",
        "      prob = rule_counter_dict[production.lhs()][production.rhs()] / lhs_counter_dict[production.lhs()]\n",
        "    else:\n",
        "      prob = 0\n",
        "    prob_production_list.append(nltk.grammar.ProbabilisticProduction(production.lhs(), production.rhs(), prob=prob))\n",
        "  return nltk.grammar.PCFG(cfg.start(), prob_production_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "ab911179",
      "metadata": {
        "deletable": false,
        "editable": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "ab911179",
        "outputId": "8e9e7324-6f45-4205-e7e7-ae3a4e5aa8d5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "    All tests passed!\n",
              "    "
            ],
            "text/html": [
              "\n",
              "    \n",
              "    \n",
              "        <p>All tests passed!</p>\n",
              "    \n",
              "    "
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "grader.check(\"probs_from_corpus\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed35f6ca",
      "metadata": {
        "id": "ed35f6ca"
      },
      "source": [
        "Now we can use the `train_pcfg` function that you wrote to build a PCFG version of the `lexicalized_arithmetic_grammar`, with rule probabilities derived from the corpus."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "6026d78e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-01-13T08:56:56.878321Z",
          "iopub.status.busy": "2025-01-13T08:56:56.878100Z",
          "iopub.status.idle": "2025-01-13T08:56:56.885099Z",
          "shell.execute_reply": "2025-01-13T08:56:56.884023Z"
        },
        "id": "6026d78e",
        "outputId": "81e3ee4e-0884-441c-d5f5-5ff12ab03e17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grammar with 35 productions (start state = S)\n",
            "    S -> S_NUM [0.0769231]\n",
            "    S -> S_ADD [0.769231]\n",
            "    S -> S_MULT [0.153846]\n",
            "    S_NUM -> NUM [1.0]\n",
            "    S_ADD -> S_NUM ADD S_NUM [0.166667]\n",
            "    S_ADD -> S_NUM ADD S_ADD [0]\n",
            "    S_ADD -> S_NUM ADD S_MULT [0.416667]\n",
            "    S_ADD -> S_ADD ADD S_NUM [0.166667]\n",
            "    S_ADD -> S_ADD ADD S_ADD [0]\n",
            "    S_ADD -> S_ADD ADD S_MULT [0]\n",
            "    S_ADD -> S_MULT ADD S_NUM [0.166667]\n",
            "    S_ADD -> S_MULT ADD S_ADD [0]\n",
            "    S_ADD -> S_MULT ADD S_MULT [0.0833333]\n",
            "    S_MULT -> S_NUM MULT S_NUM [0.916667]\n",
            "    S_MULT -> S_NUM MULT S_ADD [0]\n",
            "    S_MULT -> S_NUM MULT S_MULT [0]\n",
            "    S_MULT -> S_ADD MULT S_NUM [0]\n",
            "    S_MULT -> S_ADD MULT S_ADD [0]\n",
            "    S_MULT -> S_ADD MULT S_MULT [0]\n",
            "    S_MULT -> S_MULT MULT S_NUM [0.0833333]\n",
            "    S_MULT -> S_MULT MULT S_ADD [0]\n",
            "    S_MULT -> S_MULT MULT S_MULT [0]\n",
            "    NUM -> 'zero' [0]\n",
            "    NUM -> 'one' [0.162162]\n",
            "    NUM -> 'two' [0.27027]\n",
            "    NUM -> 'three' [0.189189]\n",
            "    NUM -> 'four' [0.162162]\n",
            "    NUM -> 'five' [0.0540541]\n",
            "    NUM -> 'six' [0.027027]\n",
            "    NUM -> 'seven' [0.0540541]\n",
            "    NUM -> 'eight' [0.0540541]\n",
            "    NUM -> 'nine' [0]\n",
            "    NUM -> 'ten' [0.027027]\n",
            "    ADD -> 'plus' [1.0]\n",
            "    MULT -> 'times' [1.0]\n"
          ]
        }
      ],
      "source": [
        "trained_probabilistic_lexicalized_arithmetic_grammar = train_pcfg(lexicalized_arithmetic_grammar, corpus)\n",
        "print(trained_probabilistic_lexicalized_arithmetic_grammar)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c836f6ac",
      "metadata": {
        "id": "c836f6ac"
      },
      "source": [
        "Observe that the probabilities of the two rules `S_ADD -> S_NUM ADD S_MULT` and `S_MULT -> S_ADD MULT S_NUM` are now different from each other. (They were both the same in the previous grammar, since you made the probabilities as uniform as possible.)\n",
        "\n",
        "We'll use NLTK's implementation of the probabilistic CKY algorithm ([`nltk.ViterbiParser`](https://www.nltk.org/api/nltk.parse.viterbi.html#nltk.parse.viterbi.ViterbiParser)) to generate the best parse for some strings according to this induced PCFG. (You'll implement this yourself in lab 3-4.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "f5f1eb06",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-01-13T08:56:56.888108Z",
          "iopub.status.busy": "2025-01-13T08:56:56.887897Z",
          "iopub.status.idle": "2025-01-13T08:56:56.891503Z",
          "shell.execute_reply": "2025-01-13T08:56:56.890659Z"
        },
        "id": "f5f1eb06"
      },
      "outputs": [],
      "source": [
        "trained_parser = nltk.ViterbiParser(trained_probabilistic_lexicalized_arithmetic_grammar)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b893a642",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "b893a642"
      },
      "source": [
        "Use this parser to parse the `example` phrase \"two plus three times four\" from above. Which parse does it return? Do you understand why?\n",
        "\n",
        "> Be careful. The parser returns a Python generator of the parses, not a list. You can't use the generator twice, so you should save the `trained_grammar_parses` as a list constructed from the generator object to pass all of the tests.\n",
        "\n",
        "<!--\n",
        "BEGIN QUESTION\n",
        "name: induced_grammar_parses\n",
        "-->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "ac6a6bde",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-01-13T08:56:56.894612Z",
          "iopub.status.busy": "2025-01-13T08:56:56.894390Z",
          "iopub.status.idle": "2025-01-13T08:56:56.900065Z",
          "shell.execute_reply": "2025-01-13T08:56:56.899186Z"
        },
        "id": "ac6a6bde"
      },
      "outputs": [],
      "source": [
        "# TODO - parse `example` using `trained_parser`\n",
        "trained_grammar_parses = list(trained_parser.parse(example.split()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "91c971a0",
      "metadata": {
        "deletable": false,
        "editable": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "91c971a0",
        "outputId": "c3a02d60-8a1f-4a79-db01-ab512503e4cf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "    All tests passed!\n",
              "    "
            ],
            "text/html": [
              "\n",
              "    \n",
              "    \n",
              "        <p>All tests passed!</p>\n",
              "    \n",
              "    "
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "grader.check(\"induced_grammar_parses\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "57b64b69",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-01-13T08:56:56.924374Z",
          "iopub.status.busy": "2025-01-13T08:56:56.924162Z",
          "iopub.status.idle": "2025-01-13T08:56:56.929505Z",
          "shell.execute_reply": "2025-01-13T08:56:56.928595Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57b64b69",
        "outputId": "49a73f6f-56a8-4628-d15f-da04f404d070"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Probability of parse tree 1 is 2.44e-03\n",
            "             S               \n",
            "             |                \n",
            "           S_ADD             \n",
            "   __________|_____           \n",
            "  |    |         S_MULT      \n",
            "  |    |      _____|______    \n",
            "S_NUM  |   S_NUM   |    S_NUM\n",
            "  |    |     |     |      |   \n",
            " NUM  ADD   NUM   MULT   NUM \n",
            "  |    |     |     |      |   \n",
            " two  plus three times   four\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for i, tree in enumerate(trained_grammar_parses):\n",
        "    print(f'Probability of parse tree {i+1} is '\n",
        "          f'{parse_probability(tree, trained_probabilistic_lexicalized_arithmetic_grammar):1.2e}')\n",
        "    tree.pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fedb5c35",
      "metadata": {
        "id": "fedb5c35"
      },
      "source": [
        "Now consider a new example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "a830270b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-01-13T08:56:56.932421Z",
          "iopub.status.busy": "2025-01-13T08:56:56.932192Z",
          "iopub.status.idle": "2025-01-13T08:56:56.935616Z",
          "shell.execute_reply": "2025-01-13T08:56:56.934752Z"
        },
        "id": "a830270b"
      },
      "outputs": [],
      "source": [
        "example2 = \"three plus nine plus two\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b69b509",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "0b69b509"
      },
      "source": [
        "How many parses with non-zero probability are there for this new expression \"three plus nine plus two\" according to the induced PCFG? Set the variable in the next cell accordingly.\n",
        "\n",
        "<!--\n",
        "BEGIN QUESTION\n",
        "name: parse_count_2\n",
        "-->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "bd966c09",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-01-13T08:56:56.938627Z",
          "iopub.status.busy": "2025-01-13T08:56:56.938425Z",
          "iopub.status.idle": "2025-01-13T08:56:56.941704Z",
          "shell.execute_reply": "2025-01-13T08:56:56.940865Z"
        },
        "id": "bd966c09"
      },
      "outputs": [],
      "source": [
        "# TODO\n",
        "example2_parse_count = len(list(trained_parser.parse(example2.split())))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "ebd29311",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-01-13T08:56:56.944429Z",
          "iopub.status.busy": "2025-01-13T08:56:56.944212Z",
          "iopub.status.idle": "2025-01-13T08:56:56.951958Z",
          "shell.execute_reply": "2025-01-13T08:56:56.951156Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebd29311",
        "outputId": "b6eeeec1-4cc0-4da4-9c45-acb37296fc1e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "len(list(trained_parser.parse(example2.split())))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f6da644",
      "metadata": {
        "id": "1f6da644"
      },
      "source": [
        "Let's examine the most probable parse for this example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "5c91adcc",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-01-13T08:56:56.954936Z",
          "iopub.status.busy": "2025-01-13T08:56:56.954597Z",
          "iopub.status.idle": "2025-01-13T08:56:56.962701Z",
          "shell.execute_reply": "2025-01-13T08:56:56.961805Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5c91adcc",
        "outputId": "0176a2c4-2151-482c-9490-3700fc059829"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Probability of parsed tree 1 is 0.00e+00\n",
            "             S              \n",
            "             |               \n",
            "           S_ADD            \n",
            "   __________|_____          \n",
            "  |    |         S_ADD      \n",
            "  |    |      _____|_____    \n",
            "S_NUM  |   S_NUM   |   S_NUM\n",
            "  |    |     |     |     |   \n",
            " NUM  ADD   NUM   ADD   NUM \n",
            "  |    |     |     |     |   \n",
            "three plus  nine  plus  two \n",
            "\n"
          ]
        }
      ],
      "source": [
        "for i, tree in enumerate(trained_parser.parse(example2.split())):\n",
        "    print(f'Probability of parsed tree {i+1} is '\n",
        "          f'{tree.prob():1.2e}')\n",
        "    tree.pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a7e922e",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "4a7e922e"
      },
      "source": [
        "<!-- BEGIN QUESTION -->\n",
        "\n",
        "In trying to parse this example, you undoubtedly obtained a single parse with zero probability.\n",
        "\n",
        "That doesn't seem right. A particular construction not occurring in the training set doesn't warrant assigning zero probability to any and all examples that use that construction. No matter how large a training set, there can always be unattested constructions. In the case at hand, one of the needed productions (`NUM -> nine`) has zero probability, which in turn followed from the fact that \"nine\" occured nowhere in the training corpus.\n",
        "\n",
        "**Question:** With a _single word_, what technique that you've learned would be appropriate to solve this problem.\n",
        "\n",
        "<!--\n",
        "BEGIN QUESTION\n",
        "name: open_response_oneword\n",
        "manual: true\n",
        "-->"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8121fec2",
      "metadata": {
        "id": "8121fec2"
      },
      "source": [
        "Smoothing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff7458e9",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "ff7458e9"
      },
      "source": [
        "<!-- END QUESTION -->\n",
        "\n",
        "<!-- BEGIN QUESTION -->\n",
        "\n",
        "**Question:** The example that we provided of an ambiguity in arithmetic expressions is admittedly quite artificial. Can you think of other (more natural) examples, in natural language or elsewhere, where this phenomenon might occur?\n",
        "\n",
        "<!--\n",
        "BEGIN QUESTION\n",
        "name: open_response_other_examples\n",
        "manual: true\n",
        "-->"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4518198",
      "metadata": {
        "id": "e4518198"
      },
      "source": [
        "There are sentences with amibiguity in natural languages. Some examples are:\n",
        "1. \"I like tea and coffee with sugar\".\n",
        "= \"(tea) and (cofee with sugar)\" or\n",
        "= \"(tea and cofee) with (sugar)\"\n",
        "\n",
        "2. \"He saw a woman with a telescope\". (Saw with telescope or a woman with telescope)\n",
        "\n",
        "3. \"Driving cars can be dangerous\". (is dangerous refering to the act of driving a car, or to the objects driving cars?)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7095791",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "b7095791"
      },
      "source": [
        "<!-- END QUESTION -->\n",
        "\n",
        "<!-- BEGIN QUESTION -->\n",
        "\n",
        "# Lab debrief\n",
        "\n",
        "**Question:** We're interested in any thoughts you have about this lab so that we can improve this lab for later years, and to inform later labs for this year. Please list any issues that arose or comments you have to improve the lab. Useful things to comment on include the following, but you're not restricted to these:\n",
        "\n",
        "* What *specific single* change to the lab would have made your learning more efficient? This might be an addition of a concept that was not explained, or an example that would clarify a concept, or a problem that would have captured a concept in a better way, or anything else you can think of that would have made this a better lab.\n",
        "* Was the lab too long or too short?\n",
        "* Were the readings appropriate for the lab?\n",
        "* Was it clear (at least after you completed the lab) what the points of the exercises were?\n",
        "* Are there general additions or changes you think would make the lab better?\n",
        "\n",
        "<!--\n",
        "BEGIN QUESTION\n",
        "name: open_response_debrief\n",
        "manual: true\n",
        "-->"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "341a2164",
      "metadata": {
        "id": "341a2164"
      },
      "source": [
        "_Type your answer here, replacing this text._"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a00109ec",
      "metadata": {
        "id": "a00109ec"
      },
      "source": [
        "<!-- END QUESTION -->\n",
        "\n",
        "\n",
        "\n",
        "# End of Lab 3-3 {-}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e09fcc8",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "3e09fcc8"
      },
      "source": [
        "---\n",
        "\n",
        "To double-check your work, the cell below will rerun all of the autograder tests."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "1c7d6e98",
      "metadata": {
        "deletable": false,
        "editable": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "1c7d6e98",
        "outputId": "672c5acd-22dd-42e2-b821-ba87e4a2ffad"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "induced_grammar_parses:\n",
              "\n",
              "    All tests passed!\n",
              "    \n",
              "\n",
              "lexicalized_parse:\n",
              "\n",
              "    All tests passed!\n",
              "    \n",
              "\n",
              "parsed_equation_result:\n",
              "\n",
              "    All tests passed!\n",
              "    \n",
              "\n",
              "parsed_trees_probs:\n",
              "\n",
              "    All tests passed!\n",
              "    \n",
              "\n",
              "pcfg_to_dict:\n",
              "\n",
              "    All tests passed!\n",
              "    \n",
              "\n",
              "probs_from_corpus:\n",
              "\n",
              "    All tests passed!\n",
              "    \n",
              "\n",
              "redundant_parses:\n",
              "\n",
              "    All tests passed!\n",
              "    \n",
              "\n",
              "uniform_lexicalized_probabilities:\n",
              "\n",
              "    All tests passed!\n",
              "    \n",
              "\n",
              "uniform_probabilities:\n",
              "\n",
              "    All tests passed!\n",
              "    \n"
            ],
            "text/html": [
              "<p><strong>induced_grammar_parses:</strong></p>\n",
              "\n",
              "    \n",
              "    \n",
              "        <p>All tests passed!</p>\n",
              "    \n",
              "    \n",
              "\n",
              "<p><strong>lexicalized_parse:</strong></p>\n",
              "\n",
              "    \n",
              "    \n",
              "        <p>All tests passed!</p>\n",
              "    \n",
              "    \n",
              "\n",
              "<p><strong>parsed_equation_result:</strong></p>\n",
              "\n",
              "    \n",
              "    \n",
              "        <p>All tests passed!</p>\n",
              "    \n",
              "    \n",
              "\n",
              "<p><strong>parsed_trees_probs:</strong></p>\n",
              "\n",
              "    \n",
              "    \n",
              "        <p>All tests passed!</p>\n",
              "    \n",
              "    \n",
              "\n",
              "<p><strong>pcfg_to_dict:</strong></p>\n",
              "\n",
              "    \n",
              "    \n",
              "        <p>All tests passed!</p>\n",
              "    \n",
              "    \n",
              "\n",
              "<p><strong>probs_from_corpus:</strong></p>\n",
              "\n",
              "    \n",
              "    \n",
              "        <p>All tests passed!</p>\n",
              "    \n",
              "    \n",
              "\n",
              "<p><strong>redundant_parses:</strong></p>\n",
              "\n",
              "    \n",
              "    \n",
              "        <p>All tests passed!</p>\n",
              "    \n",
              "    \n",
              "\n",
              "<p><strong>uniform_lexicalized_probabilities:</strong></p>\n",
              "\n",
              "    \n",
              "    \n",
              "        <p>All tests passed!</p>\n",
              "    \n",
              "    \n",
              "\n",
              "<p><strong>uniform_probabilities:</strong></p>\n",
              "\n",
              "    \n",
              "    \n",
              "        <p>All tests passed!</p>\n",
              "    \n",
              "    \n",
              "\n"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "grader.check_all()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "title": "CS187 Lab 3-3: Probabilistic context-free grammars"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}